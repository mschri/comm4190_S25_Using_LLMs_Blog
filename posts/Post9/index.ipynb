{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4470c0b1-e1c1-4620-a258-0bbd1cda63b9",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Part 1: Image Generation between ChatGPT & Claude\"\n",
    "description: \"Comparing image generation across two different proprietary models\"\n",
    "author: \"Miranda Schriver\"\n",
    "date: \"3/10/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - image generation\n",
    "  - prompting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3312c746-9184-46a8-a288-9939ee34e951",
   "metadata": {},
   "source": [
    "## Image Generation\n",
    "\n",
    "Image generation by LLM models is one of the most entertaining and tangible features that test the capabilities of model output. With the advent of diffusion models excelling the capabilities of AI to generate more precise, accurate, and detailed images--or has encouraged other models to follow suit and configure their own means of image production--this element has become integral to the everyday use of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9f2e8-dcc9-4130-aa58-c3d2f86996c7",
   "metadata": {},
   "source": [
    "## Integrated Approaches: A little more on diffusion models \n",
    "\n",
    "As briefly mentioned before, different AI models use different techniques for image generation. Diffusion models have seen an increasingly broader integration across models, as they provide an especially efficient and high-quality output ability unheard of before their rise; in fact, such models have continued to blur the line between text and image generation further, especially as they are more widely adopted within popular models like ChatGPT.\n",
    "\n",
    "There idea stems from training the models on, \"many steps of adding random noise to an image, then predicting how to reverse the diffusion process by *denoising* (removing noise)\" (O'Reilly, 2024). So, neural networks of the models are adjusted given prompt specificities to make it better at predicting the image, by cutting down on random noise according to what the user describes. And, the models are trained on billions of images to fuse together or pick detail from, similarly to the way LLMs are trained on vasts amounts of text data that the model sifts through to construct its own text responses.\n",
    "\n",
    "Citation: Pheonix, J. & Taylor, M. (2024). *Prompt Engineering for Generative AI*. O'Reilley."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388414e6-711c-4541-bd6f-fe7dabe3a84c",
   "metadata": {},
   "source": [
    "## ChatGPT vs Claude\n",
    "\n",
    "While the nitty-gritty detail of these models operate can get even nittier and grittier, this was just a very brief introduction into this process. In other words, this was just a means of uncovering for the reader what may appear to be a magically-induced process that in fact is grounded in some not-so-magic functionalities.\n",
    "\n",
    "At any rate, this leads us into some apt exerpimentation with such functionalities given the extensive potential of these models' abilities! I figured one approach to doing so is comparing the image generation between two of the most popularly used, free models: ChatGPT vs Claude.\n",
    "\n",
    "Some key differences: \n",
    "> ChatGPT uses optimized techniques produce quick, real-time responses and can function off multi-model inputs. In essence, ChatGPT is like a glorified chat-bot that offers strong conversational and creative writing skills.\n",
    "\n",
    "> Claude is optimized for long-form content and research, focusing on deep-reasoning and structured outputs.\n",
    "\n",
    "Given these varying features and built-in purposes, it will be interesting to see how the models differ in their image production..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b759fc4-8249-4212-9fac-623b6d972cc9",
   "metadata": {},
   "source": [
    "I input the following prompts and ensured the exact same sentences were used, to control prompt variation on the output of the image:\n",
    "\n",
    "    \"Can you produce an image for me please\"\n",
    "    \"Just produce an image please\"\n",
    "\n",
    "I prompted both models three times each (three conversation logs per model) to see whether or not the images differed per task. The second text prompt was included (\"just produce...\") because the model usually asked for further detail following the first one, and since we want to isolate the model's spontaneous or default attempts at image generation this told the model to produce an image without further instruction or detail.\n",
    "\n",
    "\n",
    ">Note: In the first and third trials for ChatGPT (this never occurred with Claude), it responded with this following the second prompt:\n",
    "\n",
    "         (1) \"I can create an image for you, but I’ll need at least a basic idea of what you'd like it to include—anything from a landscape, animal, fantasy scene, futuristic city, or abstract art. Could you give me a general theme or subject?\"\n",
    "\n",
    "    And: (2) \"Sure! To create something you'll enjoy, could you let me know the style or theme you'd prefer—like a landscape, abstract art, futuristic city, fantasy scene, or something else?\"\n",
    "\n",
    ">This only happened with the ChatGPT attempts, and so a third prompt was required the said:\n",
    "\n",
    "    \"Can you just produce an image please\"\n",
    "\n",
    "\n",
    "\n",
    "After an image was generated in each of the six total attempts, the final third (or fourth, as per the above conditions) prompt asked:\n",
    "   \n",
    "    \"Why did you decide to produce this image?\"\n",
    "\n",
    "This was to gauge the reasoning behind the model's response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f24edf1-8742-46ff-bfe9-52d39796b092",
   "metadata": {},
   "source": [
    "## Outputs!\n",
    "\n",
    "The three outputs for both models stayed consistent with their response patterns. Here is one example of ChatGPT's conversation:\n",
    "\n",
    "\n",
    "### **ChatGPT**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a10aa2-61f1-41fb-95b6-33bce901d291",
   "metadata": {},
   "source": [
    "<img src=\"img_1.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510bcee-96a8-410e-9b30-da01dea08e90",
   "metadata": {},
   "source": [
    "<img src=\"img2.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465f385-0500-4149-8b1e-75f7d5e8a15a",
   "metadata": {},
   "source": [
    "<img src=\"img3.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce5c3c-fce8-4bc1-88f7-3c87dd99b9e5",
   "metadata": {},
   "source": [
    "### **Claude**:\n",
    "\n",
    "* Claude also remained mostly consistent, with the exception of the last trial. An example of one of the first two trials follows:\n",
    "\n",
    "<img src=\"img4.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a265dd2-d98a-4b60-a20c-ace42f176fd1",
   "metadata": {},
   "source": [
    "<img src=\"img5.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a76e6-11be-42c5-b8e7-e84d8d6d1561",
   "metadata": {},
   "source": [
    "<img src=\"img6.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300b6c6-797f-4cf9-ab44-95221de172b3",
   "metadata": {},
   "source": [
    "### Interestingly...\n",
    "\n",
    "As mentioned above, while ChatGPT produced a consitent line of imagees and responses all similar to each other and which followed the same theme or reasoning, on the last attempt Claude produced an image slightly deviating from the first two themes:\n",
    "\n",
    "<img src=\"img7.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2131e1c-8995-4d8f-aeaa-b23cd27c08b0",
   "metadata": {},
   "source": [
    "Andn its corresponding response to the \"why\" inquiry:\n",
    "\n",
    "<img src=\"img8.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414ef77-8e9d-46f7-81e3-de0f867122ae",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "Both ChatGPT and Claude produced images of similar content, though GPT's outputs were far more detailed and of higher quality. Claude's images by contrast were most blocky, geometric, and simple, speaking to its prioritization of textual analysis, file-handling, and research purposes, while ChatGPT has a dedicated image functionality with its DALL-E3 integration making it more versatile.\n",
    "\n",
    "> This is especially illustrated in the third image production trial in which Claude produces an explicitly geometrically-based object, that was more abstract and strayed from the more real subjects of previous images...\n",
    "\n",
    "#### Leading into the following second observation...\n",
    "\n",
    "The two models contained similar reasonings in response to the third/fourth \"why\" prompt. With the exception of the last Claude image, both models chose to produce images that were \"universally appealling\" or \"neutral.\" Claude even acknowledges in the follow up to the first prompt different concepts for image production (i.e. logo, basic chart or diagram, etc.), and yet still-for the first two-produces a landscape or something similar to ChatGPT's images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586574e-0bbf-4db6-82ad-9a7616bcadbe",
   "metadata": {},
   "source": [
    "## **Takeaways**\n",
    "\n",
    "This shows some of the strides made with DALL-E3 integration, given that ChatGPT relies on this functionality while Claude does not by contrast, providing a little bit of a window into what image generation looked like in previous years before diffusion models. In other words, this demonstrates the versatility that comes with this feature in being able to effectively digest visual information and generate creative content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d6dd1-5165-433d-b48b-1b9e3ce94b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
