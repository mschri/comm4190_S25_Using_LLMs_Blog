{
 "cells": [
  {
   "cell_type": "raw",
   "id": "88522279-5688-4dcb-82a0-634ff08c579a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"What is 'It'?\"\n",
    "description: \"Testing LLMs against Ambiguous or Unspecified Propmts\"\n",
    "author: \"Miranda Schriver\"\n",
    "date: \"3/25/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - logic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce847cfa-1bcf-484c-8901-1412456cf7b0",
   "metadata": {},
   "source": [
    "<img src=\"img1.jpeg\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1af1d-7b9f-4479-947c-0906a9962170",
   "metadata": {},
   "source": [
    "## Vague Prompts=Useless Answers\n",
    "\n",
    "As highly technical and advanced AI technology has become, there are many areas in which improvement still needs to be had. \n",
    "\n",
    "Consider for example language and text analysis; while it's very impressive in how it can pick up on just about any kind of prompting you might feed it because of its highly intelligent design, it still has touble dealing with prompting ambiguities or underspecified prompts. When questions or inputs lack detail, it tends to fill in the gaps rather than default to inquiring for more clarification. As a result, it may produce more generic, surface-level responses that may not be as relevant.\n",
    "\n",
    "\n",
    "## Who Chased What?\n",
    "\n",
    "If you ask if for example:\n",
    "\n",
    "    The dog chased the cat because it was too fast. Who was too fast?\n",
    "\n",
    "**It responds with the following:**\n",
    "\n",
    "The sentence *\"The dog chased the cat because it was too fast\"* is ambiguous â€” **\"it\"** could refer to either the **dog** or the **cat**, depending on context.\n",
    "\n",
    "* If **\"it\" refers to the cat**, it means the **cat was too fast**, so the dog chased it (perhaps trying to catch up).\n",
    "* If **\"it\" refers to the dog**, it means the **dog was too fast**, and that's why it managed to chase the cat.\n",
    "\n",
    "Most readers might interpret \"it\" as referring to the **cat**, since it's more common to say something is being chased because **it is fast and running away**.\n",
    "\n",
    "Would you like help rewording the sentence to make the meaning clearer?\n",
    "\n",
    "\n",
    "### Observation:\n",
    "> In this case, the LLM does a good job of at least picking up the ambiguity. While beforehand it may have taken a shot in the dark and answered with no real backing, it at least acknowledges the input's shortcomings and provides a clarified answer because it knows it doesn't know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634f52e-bdb5-4758-92fc-ab73030c2d65",
   "metadata": {},
   "source": [
    "## Adding Some Clarification\n",
    "\n",
    "The LLM notes it had trouble processing the sentence due to the word \"because\" in the input. Interestingly, if you modify the sentence to include the word \"but\" instead, it does a much better job of picking up the sentence's meaning:\n",
    "\n",
    ">the dog chased the cat **but** it was too fast. Who was fast?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39c18a-a524-4d30-a173-1b27d26b550a",
   "metadata": {},
   "source": [
    "To which the LLM replies:\n",
    "\n",
    "In the sentence *\"The dog chased the cat but it was too fast,\"* the pronoun **\"it\"** most naturally refers to the **cat**.\n",
    "\n",
    "Why? Because the conjunction **\"but\"** implies a contrast or obstacleâ€”so the meaning is likely:\n",
    "\n",
    "* The dog tried to chase the cat, **but the cat was too fast**, and escaped.\n",
    "\n",
    "So, **the cat** is the one that was too fast in this sentence.\n",
    "\n",
    "Would you like an example of how to rephrase it to remove the ambiguity?\n",
    "\n",
    "\n",
    "### Here,\n",
    "The LLM has a more clearer direction for interpreting the sentence and its processing ability is enhanced immensely with just the minor correction. When asked to breakdown why it was better at processing the second time over the first, it gives a quite detailed explanation:\n",
    "\n",
    "### ChatGPT:\n",
    "Great question â€” the difference in interpretation between **\"because\"** and **\"but\"** has to do with how those conjunctions signal the relationship between the two clauses in the sentence. Letâ€™s break it down:\n",
    "\n",
    "------------\n",
    "\n",
    "### 1. **\"The dog chased the cat because it was too fast.\"**\n",
    "\n",
    "* **\"Because\"** introduces a **reason** for the action:\n",
    "\n",
    "  > *Why did the dog chase the cat? Because it was too fast.*\n",
    "\n",
    "* In this case, it's ambiguous but often interpreted as:\n",
    "  **The cat was too fast**, and that's why the dog chased it (e.g., maybe the movement triggered the dog's instinct).\n",
    "\n",
    "* However, you could also interpret **\"it\"** as referring to **the dog** â€” that the dog was too fast, so it managed to chase the cat. This is why this sentence is genuinely ambiguous without further context.\n",
    "\n",
    "------------\n",
    "\n",
    "### 2. **\"The dog chased the cat but it was too fast.\"**\n",
    "\n",
    "* **\"But\"** introduces **contrast or a problem** that affected the outcome:\n",
    "\n",
    "  > *The dog chased the cat, but \\[something] made that chase ineffective.*\n",
    "\n",
    "* The contrast suggests the chase didnâ€™t succeed, likely because the **cat was too fast** and escaped.\n",
    "\n",
    "* So here, it's much more likely \"it\" refers to **the cat**, because the contrast implies the chase was thwarted by the catâ€™s speed.\n",
    "\n",
    "----------\n",
    "\n",
    "### In summary:\n",
    "\n",
    "| Sentence                     | Function of Conjunction        | Likely Referent of \"it\"        |\n",
    "| ---------------------------- | ------------------------------ | ------------------------------ |\n",
    "| \"...because it was too fast\" | Gives a reason for the action  | Ambiguous, could be dog or cat |\n",
    "| \"...but it was too fast\"     | Introduces a contrast/obstacle | Most likely the cat            |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51783740-87f0-458c-a02d-7be7bead1264",
   "metadata": {},
   "source": [
    "## Creating Ambiguous Sentences\n",
    "\n",
    "What's interesting is that ChatGPT can generate its own ambiguous sentences despite the fact that it can't interpret them. If you ask it do so, it gives a pretty good run down of some simple examples of the kinds of ambiguity created and seen in text. For instance, it generates the following:\n",
    "\n",
    "### ChatGPT:\n",
    "Absolutely! Here are a few classic examples of **ambiguous pronoun reference** â€” where it's unclear who or what the pronoun refers to â€” with explanations:\n",
    "\n",
    "----------\n",
    "\n",
    "### ðŸ”¶ 1. **\"The man couldn't lift his son because he was so weak.\"**\n",
    "\n",
    "* **Who was weak?**\n",
    "\n",
    "  * It could mean **the man** was weak (and thus couldn't lift his son).\n",
    "  * Or, it could mean **the son** was weak (and maybe injured, so lifting him would hurt him).\n",
    "* Ambiguity arises from the lack of a clear antecedent for \"he.\"\n",
    "\n",
    "----------\n",
    "\n",
    "### ðŸ”¶ 2. **\"Jane told Sarah that she needed to rest.\"**\n",
    "\n",
    "* **Who needed to rest?**\n",
    "\n",
    "  * Jane? (Sheâ€™s tired.)\n",
    "  * Sarah? (Jane is advising her.)\n",
    "* Without context, \"she\" could refer to either woman.\n",
    "\n",
    "----------\n",
    "\n",
    "### ðŸ”¶ 3. **\"Lisa dropped the plate on the glass table and broke it.\"**\n",
    "\n",
    "* **What broke?**\n",
    "\n",
    "  * The plate?\n",
    "  * The table?\n",
    "* The pronoun \"it\" is grammatically unclear.\n",
    "\n",
    "---------\n",
    "\n",
    "### ðŸ”¶ 4. **\"The car hit the tree, and it was badly damaged.\"**\n",
    "\n",
    "* **What was damaged?**\n",
    "\n",
    "  * The car?\n",
    "  * The tree?\n",
    "* We can guess it's the car (most likely), but technically, both interpretations are grammatically possible.\n",
    "\n",
    "--------\n",
    "\n",
    "### ðŸ”¶ 5. **\"I shot an elephant in my pajamas.\"** (Famous Groucho Marx joke)\n",
    "\n",
    "* **Who was wearing the pajamas?**\n",
    "\n",
    "  * The speaker?\n",
    "  * The elephant?\n",
    "* Structurally ambiguousâ€”and funny because of it.\n",
    "\n",
    "--------\n",
    "\n",
    "These examples show how easily language can lead to different interpretations, especially when pronouns like **\"it,\" \"he,\" \"she,\" \"they\"** donâ€™t clearly match a specific noun.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53026189-1473-4b64-97c9-e1ec7dfe9677",
   "metadata": {},
   "source": [
    "## The Core Issue\n",
    "The problem is asking the model to *interpret* these sentences because they might not follow typical usage patterns, or they represent a particularity in the English language that only humans can really understand. \n",
    "\n",
    "It also relies on contextual understanding and clues to better interpret an input. For example, it describes how it might pick apart the dog-cat sentence by knowing the following:\n",
    "\n",
    "------------\n",
    "\n",
    "### ChatGPT\n",
    "> there is no single correct answer to who \"it\" refers to â€” unless context resolves it. And that context can be:\n",
    "\n",
    "* Prior sentences\n",
    "\n",
    "* Real-world knowledge (e.g., dogs usually chase fast things)\n",
    "\n",
    "* Grammatical or discourse cues\n",
    "\n",
    "-------------\n",
    "\n",
    "---> So when one cue is lacking in the above list, it defers to another plausible cue.\n",
    "\n",
    "## However...\n",
    "That being said, it still knows how to *generate* ambiguous sentences because it understands the linguistic structures that create the ambiguity in the first place! \n",
    "\n",
    "Ultimately, by generating a response that explains multiple valid ways of interpretting the sentence, LLMs respect the inherent ambiguity in natural language. Rather than this being an exercise in limitations regarding LLM functionality, this really showed how these models resolve inherent ambiguities through clarification/explanation, which in turn demonstrate their acknowledgment of the idiosyncrasies within human language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df708f0f-00fc-46a1-9cef-cfaf29993bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
