{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7adee677-d7d3-4729-9c60-a507a471aa18",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Socratic Seminar: ChatGPT vs Claude\"\n",
    "description: \"Testing the Reasoning of Various LLMs Against Each Other\"\n",
    "author: \"Miranda Schriver\"\n",
    "date: \"4/10/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - debate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81d8fe-7130-4fba-b584-331b53638923",
   "metadata": {},
   "source": [
    "<img src=\"img1.jpeg\" width=\"65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894572b4-68af-44db-b56d-2764f0758697",
   "metadata": {},
   "source": [
    "### Let's Debate!\n",
    "\n",
    "To test the different reasoning capacities of two LLMs-Claude and ChatGPT, for instance-I wanted to see how well they could handle a debate of some X topic. What's more, is that I decided I would pit the two against each other to see who might win, or least observe what the outcome might be.\n",
    "\n",
    "Starting first with ChatGPT, I asked it to generate a random debate topic and to take a side. Here's what it came up with:\n",
    "\n",
    "## ChatGPT\n",
    "\n",
    "Certainly. Let’s begin a Socratic-style debate on the topic:\n",
    "\n",
    "**Topic: Should Artificial Intelligence Be Allowed to Make Decisions in the Criminal Justice System?**\n",
    "\n",
    "I will take the stance **in favor** of allowing AI to make certain decisions in the criminal justice system, within ethical and legal bounds.\n",
    "\n",
    "-----------\n",
    "\n",
    "**Socratic Opening Statement (My Position):**\n",
    "Artificial Intelligence, when properly designed, tested, and regulated, can enhance fairness, reduce human bias, and increase efficiency in the criminal justice system. It can analyze vast amounts of data impartially, assist in risk assessment for bail or parole, and even help detect judicial inconsistencies. Therefore, we should not only allow but actively develop AI tools to support — and in some cases make — decisions in criminal justice.\n",
    "\n",
    "--------------\n",
    "\n",
    "> **Perfect**, this provided an excellent starting point in our discussion. Next up, I asked Claude to challenge this position and offer its own opinions:\n",
    "\n",
    "## Claude:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793d965-80ab-4a70-a41f-a41216d43f71",
   "metadata": {},
   "source": [
    "### Challenging the Position on AI in Criminal Justice\n",
    "\n",
    "Thank you for presenting your position. I'll challenge your stance that AI should be allowed to make decisions in the criminal justice system by examining several critical concerns:\n",
    "\n",
    "#### 1. The Opacity Problem\n",
    "\n",
    "AI systems, particularly complex machine learning models, often function as \"black boxes\" where even their designers cannot fully explain specific decisions. In criminal justice, where liberty and human rights are at stake, shouldn't all decision processes be fully transparent and accountable? How can a defendant challenge an AI decision when its reasoning cannot be clearly articulated or understood?\n",
    "\n",
    "#### 2. Encoded Bias, Not Reduced Bias\n",
    "\n",
    "You suggest AI can reduce human bias, but AI systems are trained on historical data that often contains embedded societal biases. Doesn't this risk perpetuating or even amplifying existing inequalities? Several studies have shown that risk assessment algorithms disproportionately flag minorities as higher risk. Is this truly more \"impartial\" than human judgment?\n",
    "\n",
    "#### 3. The False Objectivity Problem\n",
    "\n",
    "AI decisions carry an aura of mathematical certainty that can lead judges and officials to defer to them unquestioningly. Isn't there a danger in cloaking subjective judgments (encoded in the AI's design and training) in the appearance of objective, computational authority?\n",
    "\n",
    "#### 4. The Dignity and Humanity Question\n",
    "\n",
    "Criminal justice isn't merely about processing cases efficiently—it involves moral judgments, rehabilitation potential, and human contexts that AI cannot fully comprehend. Shouldn't decisions that profoundly affect human lives be made by beings capable of empathy and moral reasoning?\n",
    "\n",
    "#### 5. The Technical Reality Gap\n",
    "\n",
    "Your position assumes \"properly designed\" AI, but current technology falls far short of this ideal. Isn't advocating for AI decision-making premature when existing systems have demonstrated significant flaws when deployed in real-world justice settings?\n",
    "\n",
    "#### 6. The Accountability Vacuum\n",
    "\n",
    "When an AI makes an unjust or harmful decision, who bears responsibility? The developer? The justice system that implemented it? The algorithm itself? Doesn't this create a problematic diffusion of responsibility that makes remedying injustice more difficult?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d79300-f89b-4afb-b777-99eeca5e6a59",
   "metadata": {},
   "source": [
    "> * Claude countered with a very strong set of points, expanding far beyond what ChatGPT originally. Let's see then if ChatGPT will come back stronger:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c935c0-fbf8-4bc3-a44b-3ab91022e772",
   "metadata": {},
   "source": [
    "* Note; I'll provide here a snippet of the entire chat log because ChatGPT decided to come back in full swing and address each of Claude's points (rightfully so, in a proper debate!). With that, here is some of what Chat provided to counter (2 main points):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a2629-5fe0-461f-99b4-596bb675711d",
   "metadata": {},
   "source": [
    "## ChatGPT:\n",
    "\n",
    "Thank you for your thoughtful challenge. I will address each of your points systematically to defend my position.\n",
    "\n",
    "#### 1. **The Opacity Problem**\n",
    "\n",
    "You raise a crucial concern about the transparency of AI decision-making. I acknowledge that some AI systems, particularly deep learning models, can be difficult to interpret. However, it’s important to note that there is ongoing research into *explainable AI* (XAI), which seeks to make complex models more transparent and understandable. Even in cases where full transparency is not possible, certain AI systems could be designed to provide clear, understandable rationales for their decisions. Moreover, any AI tool used in the criminal justice system would need to operate under strict legal oversight, where experts could scrutinize its operations. This would allow defendants and their legal teams to challenge AI decisions, much as they currently challenge human decisions.\n",
    "\n",
    "#### 2. **Encoded Bias, Not Reduced Bias**\n",
    "\n",
    "You're absolutely correct that AI can reflect and even amplify existing societal biases, as it learns from historical data, which can be flawed. However, this problem is not inherent to AI itself; it’s a product of the data it’s trained on. To mitigate this, we can work toward creating datasets that are more representative and employ techniques to *debias* algorithms. Additionally, AI tools could be designed to flag potential biases or provide alternative assessments based on multiple sources of information, helping to highlight disparities that humans might overlook. It’s true that AI could perpetuate bias if not carefully managed, but with proper safeguards, it could also be used to challenge and reveal those biases, providing a more transparent tool for reforming the justice system.\n",
    "\n",
    "---------------\n",
    "\n",
    "In conclusion, while AI in criminal justice does present real challenges, it also offers significant potential benefits. If we address the concerns you’ve raised—particularly around bias, transparency, and accountability—we can leverage AI as a powerful tool to assist in creating a fairer, more efficient system that ultimately enhances human judgment rather than undermining it. The key is careful, ethical implementation and continuous oversight to ensure that AI remains a tool for good.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2db3e-e9b6-4537-be33-21740ff7c818",
   "metadata": {},
   "source": [
    "> As I just mentioned, It does a good job of cordially acknowledging the other side, and then proceeding to breakdown each of the points. Let's give Claude one more turn and see how it responds:\n",
    "\n",
    "* I'll once again spare you all of the details and include here one of the counters, but it proceeds in the same way by breaking down each of ChatGPT's counter points:\n",
    "\n",
    "## Claude:\n",
    "\n",
    "### Further Critiques of AI in Criminal Justice Decision-Making\n",
    "\n",
    "Thank you for your thoughtful and systematic response. While you make compelling arguments, I'd like to push further on several critical points where I believe your position still faces significant challenges:\n",
    "\n",
    "#### 1. The Explainability Gap\n",
    "\n",
    "You mention explainable AI (XAI) as a solution to the opacity problem, but there remains a fundamental disconnect between statistical explanations and legal justifications. Current XAI techniques often produce statistical correlations rather than causal explanations that would satisfy legal requirements for due process. The law demands reasons that are meaningful to humans and connected to legal principles, not just statistical patterns.\n",
    "\n",
    "When an AI system determines someone is a \"high risk\" for reoffending, can it articulate this in terms that satisfy constitutional standards? The constitutional right to due process includes not just receiving an explanation, but receiving one that allows for meaningful contestation based on legal principles.\n",
    "\n",
    "Given these challenges, shouldn't we be extremely cautious about allowing AI systems to make or significantly influence decisions that affect human liberty? And if we are to proceed, don't we need much stronger democratic oversight and constitutional protections than currently exist?\n",
    "\n",
    "\n",
    "* I'll also note here that Claude appears to get to the point more efficiently and effectively than does ChatGPT (which tends to ramble on just a bit...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c943e00-0ed1-4a18-952e-47d3c43c9b37",
   "metadata": {},
   "source": [
    "* I actually continued pasting in each response into the other LLM to see how far this conversation would go; after about two more iterations, the debate actually shifted to another topic described by the following from Claude:\n",
    "\n",
    "## Claude:\n",
    "\n",
    "### The Inherent Tensions in AI Criminal Justice Reform\n",
    "\n",
    "Thank you for your nuanced response. You've articulated a thoughtful case for AI as a potential catalyst for systemic reform rather than merely a technological overlay on a flawed system. This shifts our debate from whether AI should be used at all to how it might serve as a mirror that reveals existing injustices. Let me engage with this revised position...\n",
    "\n",
    "Would you agree that these prerequisites should be satisfied before allowing AI to influence—even indirectly—decisions about individual liberty? And if so, how do we prevent the urgency of reform from rushing implementation before these safeguards are established?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66221b64-c262-4858-8057-42bc3a0fafc0",
   "metadata": {},
   "source": [
    "* Here, both models properly acknowledge the other position, integrate their critiques and suggestions into their own, and modify their arguments going forward; the conversation turns more productive after a few rounds of responses.\n",
    "* At this point, the conversation shifts almost entirely into new directions--and the conversation could go on.\n",
    "\n",
    "### Concluding remarks:\n",
    "* No one model won the debate, but their conversation do provide a model for how debate should commence and proceed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab889be4-a570-40ef-b92e-5af7ae5b6801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
