[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Experimenting with LLMs",
    "section": "",
    "text": "Resolving Word-Plays & Plays-On-Words\n\n\n\nLLMs\n\nPrompting\n\nLanguage\n\n\n\nPrompting ChatGPT To Resolve Various Paradoxes\n\n\n\n\n\nApr 5, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nHow Well Can ChatGPT Speak Spanish?\n\n\n\nLLMs\n\nPrompting\n\nLanguage\n\n\n\nTesting ChatGPT’s Ability to Process Language\n\n\n\n\n\nApr 1, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nCreativity with Constraints\n\n\n\nPrompting\n\ncreativity\n\nprompt engineering\n\n\n\nTesting the Creative Limits of ChatGPT\n\n\n\n\n\nMar 29, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nHow About Another Puzzle?\n\n\n\nLLMs\n\npuzzles\n\n\n\nPrompting Different LLMs to Solve Various Puzzle Challenges Part 2\n\n\n\n\n\nMar 25, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is ‘It’?\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nTesting LLMs against Ambiguous or Unspecified Propmts\n\n\n\n\n\nMar 25, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nRiddle Me This: How Good is Your Puzzle Solving, ChatGPT?\n\n\n\nLLMs\n\npuzzles\n\n\n\nPrompting Different LLMs to Solve Various Puzzle Challenges\n\n\n\n\n\nMar 23, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nWhy Can’t ChatGPT Remain Consistent?\n\n\n\nLLMs\n\nimage analysis\n\nprompting\n\n\n\nTesting the Limits of Diffusion Models With Image Generation\n\n\n\n\n\nMar 19, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nIs ChatGPT Utilitarian or Deontological?\n\n\n\nLLMs\n\nethics\n\nprompting\n\n\n\nTesting the effects of priming on ethical responses of LLMs\n\n\n\n\n\nMar 17, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Image Analysis between ChatGPT & Claude\n\n\n\nLLMs\n\nimage analysis\n\nprompting\n\n\n\nComparing image analysis between two LLMs\n\n\n\n\n\nMar 12, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nPart 1: Image Generation between ChatGPT & Claude\n\n\n\nLLMs\n\nimage generation\n\nprompting\n\n\n\nComparing image generation across two different proprietary models\n\n\n\n\n\nMar 10, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s ChatGPT’s Opinion on WW1?\n\n\n\npriming\n\nLLMs\n\nprompting\n\n\n\nExamining the Effects of Priming on Model Output\n\n\n\n\n\nMar 5, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nContext Window Memory Test\n\n\n\ncontext windows\n\nLLMs\n\nprompting\n\n\n\nExamining How Much Context a Model Retains Over Conversation\n\n\n\n\n\nFeb 28, 2025\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nDecode the Message\n\n\n\nLLMs\n\ncontext understanding\n\n\n\nHow Well Can LLMs Predict Patterns and Mappings?\n\n\n\n\n\nFeb 20, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nFill in the Blank\n\n\n\nLLMs\n\nprobability\n\nembedding\n\n\n\nTesting Probabilistic Text Generation\n\n\n\n\n\nFeb 17, 2025\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nModel Comparison\n\n\n\nLLMs\n\nopen weight models\n\nprompting\n\n\n\nTesting out Different Open Weight Models\n\n\n\n\n\nFeb 14, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Get the Best Response\n\n\n\nLLMs\n\nprompting\n\nprompt engineering\n\n\n\nPrompt Engineering & Response Optimization\n\n\n\n\n\nFeb 10, 2025\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Mdoels & Word Prediction\n\n\n\nLLMs\n\nword prediction\n\nprobability\n\n\n\nHow Do Large Language Models Generate Answers\n\n\n\n\n\nFeb 5, 2025\n\n\nMiranda Schriver\n\n\n\n\n\n\n\n\n\n\n\n\nChatgpt: Can It Really Perform Simple Calculations?\n\n\n\n-generative AI -Prompting -Logic, calculations\n\n\n\nUsing Chatgpt to answer math problems\n\n\n\n\n\nFeb 3, 2025\n\n\nAn LLM user\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Post6_Feb_17-23/Post6.html",
    "href": "posts/Post6_Feb_17-23/Post6.html",
    "title": "Decode the Message",
    "section": "",
    "text": "As we know, LLMs have an acute pattern recognition and contextual understanding based on the prompts that users feed it. It’s well-versed in a variety of problems and puzzles people have managed to think up, and its intelligent includes a number of techniques involved in language processing. For example, it relies primarily on its language modeling (the large textual dataset it’s trained on), along with basic trial and error measures, simple deciphering methods, and other coding mechanisms that anyone could likely implement themselves.\n\n\nIn the spirit of stretching prompt complexity to see how LLMs respond and react, I came up with a relatively simple code using a one-to-one character mapping, and seeing if the LLM could decipher the sentences I fed it. This was to test the contextual understanding and pattern recognition capabilities of LLMs, and see how quickly (or slowly) they can pick up a complex input.\nLet’s test using one of the latest ChatGPT models:\nthe coded message: )3””9,,_)92_-43_697_59:-6 \nAnd the answer: Hello, how are you today\n\n(where double comma = a comma, and _ represents a space between words.)\n\n\nThe mapping is as follows: each of the letters on a phone keyboard equate to the corresponding characters located in the same positions within the 123 keyboard\n\nPicture for Reference:\n“Original” keyboard (standard QWERTY keyboard) &gt; This is the standard, default keyboard layout for a phone \n“Alternate” keyboard &gt; When you press the “123” button on the keyboard in the lower left-hand corner, the alternate character keyboard (for numbers, punctuation marks, etc.) appear:\n\n\n\nSo for instance, Q=1, P=0, A=-, N=!, and so forth…\nWith that, let's see whether or not/how fast one of ChatGPT's latest models can pick up this pattern!\n\n\n\n\nUnderstandably, the LLM doesn’t immediately pick up the pattern of the coded message, as anyone upon first glance can also agree, it appears to look like straight gibberish.\n\nLet’s see what happens when we give it another, fairly allusive hint:\n\n\n\n\n\n\nAs per the second half of its response to the second query, we can see that the LLM already picks up a clue/sense as to what the mapping might involve!\n\n\nThese prompts and corresponding LLM outputs demonstrate the extent to which these models are not purely glorified auto-completion or password-cracking algorithms; as previously mentioned, they incorporate a combination of these functionalities, alongside an intricate system of language processing and contextual understanding.\n\nNote: the second query did not give any mapping hints!\n\n\nTrying a third query (that makes no reference to the explicit mappings)"
  },
  {
    "objectID": "posts/Post6_Feb_17-23/Post6.html#llms-and-contextual-understanding",
    "href": "posts/Post6_Feb_17-23/Post6.html#llms-and-contextual-understanding",
    "title": "Decode the Message",
    "section": "",
    "text": "As we know, LLMs have an acute pattern recognition and contextual understanding based on the prompts that users feed it. It’s well-versed in a variety of problems and puzzles people have managed to think up, and its intelligent includes a number of techniques involved in language processing. For example, it relies primarily on its language modeling (the large textual dataset it’s trained on), along with basic trial and error measures, simple deciphering methods, and other coding mechanisms that anyone could likely implement themselves.\n\n\nIn the spirit of stretching prompt complexity to see how LLMs respond and react, I came up with a relatively simple code using a one-to-one character mapping, and seeing if the LLM could decipher the sentences I fed it. This was to test the contextual understanding and pattern recognition capabilities of LLMs, and see how quickly (or slowly) they can pick up a complex input.\nLet’s test using one of the latest ChatGPT models:\nthe coded message: )3””9,,_)92_-43_697_59:-6 \nAnd the answer: Hello, how are you today\n\n(where double comma = a comma, and _ represents a space between words.)\n\n\nThe mapping is as follows: each of the letters on a phone keyboard equate to the corresponding characters located in the same positions within the 123 keyboard\n\nPicture for Reference:\n“Original” keyboard (standard QWERTY keyboard) &gt; This is the standard, default keyboard layout for a phone \n“Alternate” keyboard &gt; When you press the “123” button on the keyboard in the lower left-hand corner, the alternate character keyboard (for numbers, punctuation marks, etc.) appear:\n\n\n\nSo for instance, Q=1, P=0, A=-, N=!, and so forth…\nWith that, let's see whether or not/how fast one of ChatGPT's latest models can pick up this pattern!\n\n\n\n\nUnderstandably, the LLM doesn’t immediately pick up the pattern of the coded message, as anyone upon first glance can also agree, it appears to look like straight gibberish.\n\nLet’s see what happens when we give it another, fairly allusive hint:\n\n\n\n\n\n\nAs per the second half of its response to the second query, we can see that the LLM already picks up a clue/sense as to what the mapping might involve!\n\n\nThese prompts and corresponding LLM outputs demonstrate the extent to which these models are not purely glorified auto-completion or password-cracking algorithms; as previously mentioned, they incorporate a combination of these functionalities, alongside an intricate system of language processing and contextual understanding.\n\nNote: the second query did not give any mapping hints!\n\n\nTrying a third query (that makes no reference to the explicit mappings)"
  },
  {
    "objectID": "posts/Post6_Feb_17-23/Post6.html#was-it-right",
    "href": "posts/Post6_Feb_17-23/Post6.html#was-it-right",
    "title": "Decode the Message",
    "section": "Was it right?!",
    "text": "Was it right?!\nThe LLM was right!….mostly… It was slightly off in guessing the portion of the sentence that included the 697, and attributing it to a mapping of the question mark character, but once again it’s impressive to note how the model can decode messages with contextual clues that make no explicit reference to a mapping hint."
  },
  {
    "objectID": "posts/Post18/index.html#word-play",
    "href": "posts/Post18/index.html#word-play",
    "title": "Resolving Word-Plays & Plays-On-Words",
    "section": "Word Play",
    "text": "Word Play\nReading the following sentence and see if you can work out what it’s saying:\n\nImagine if imaginary numbers were in fact imaginary. How would you disprove then the existence of imaginary numbers given that they are imaginary?\n\nThis is definitely a confusing sentence, and it’s intended to be! The average person will take a double take, or two, and still may not quite understand the essence of what the sentence is trying to say.\nTo test ChatGPT’s reasoning and comprehension, I asked it this query to see how well it might be able to pick it apart. It’s response was this:\n\n\nChatGPT:\nAh, now we’re diving into a meta-mathematical paradox — love it.\nYou’re proposing:\n\n“Imagine imaginary numbers are actually imaginary — i.e., they don’t exist.”\n\nThen ask:\n\n“How would you disprove their existence given they are imaginary?”\n\nThat’s a bit like saying:\n\n“Assume unicorns are real, and now prove they aren’t.”\n\nThis is a self-negating premise: you’re asking for a disproof from within an assumption that already denies the thing you’re disproving. But let’s explore it as rigorously as we can.\nTo “disprove” imaginary numbers from within the assumption that they’re imaginary (nonexistent) is like trying to disprove color vision in a world that only sees grayscale.\n\nTL;DR\n\nYou can’t logically disprove imaginary numbers if they’re already defined and proven consistent. Assuming they don’t exist leads to a broken, incomplete version of math that fails to describe the real world — ironically making imaginary numbers more “real” than ever.\n\n\nTo summarize, ChatGPT does a pretty good job of breaking apart the sentence and understand what it’s trying to say, that being trying to disprove something assumed to be not real that does in fact exist…\n\n\n\nTo continue testing it’s abilities…\nI fed another prompt into ChatGPT along similar lines, this time regarding paradoxes:\n\nInput: “Paradoxically, some paradoxes are not paradoxes in themselves, but are still considered paradoxes because of their paradoxical nature of not being paradoxical when they named paradoxes. Can you give me an example of this kind of paradox?”\n\n\nThe intention here is to obviously be as convoluted as possible (to a point where I don’t even necessarily know what I’m saying…), to see where and when it might choose to fill in knowledge or understanding gaps. So its response:\n\n\n\n\n\n\n\n### ChatGPT:\n\n\n\n\n* Impressively, Chat appears to know what I’m talking about, even offering an example of what I’m referring to (citing an example of a named paradox that is so because it’s not actually paradoxical)!\n\n\nThese experiments clearly show just how good the technology is at resolving discrepancies in text, identifying underlying reasoning, and noting any potential contradictions. It attempts to “understand” things by following the pattern of the logic and mimicking its sentiment. Of course, at the end of the day this all boils down to probability assignments of words and phrases that best suit the logic of the query. But it’s interesting how well it seemingly comprehends almost anything that’s put into it!\n\n\nI decided to give it one last input to hammer home this idea: &gt; Can you give me an example of something that is incorrectly assumed to be incorrect, or incorrectly assumed to be correct, because it may also be both correct and incorrect and therefore you can’t immediately assume incorrectness or correctness, and relatedly your initial assumption is incorrect at large?\n\n\n\n\n\nChatGPT:\nAbsolutely—what you’re describing is a kind of meta-paradox, where the act of assuming correctness or incorrectness becomes itself the error due to the ambiguity or duality of the underlying claim. Here’s a classic-style example that fits your description:\n\nExample: The Liar’s Reflection\nStatement: “This statement is false.”\nAt first glance, many people assume it’s simply incorrect (or nonsensical). But let’s break it down:\n\nIf the statement is true, then what it says must hold—so it’s false.\nBut if it’s false, then it’s not the case that “this statement is false,” which would mean it’s true.\n\nSo the statement seems to be both true and false at the same time. The initial assumption—whether assuming it is correct (true) or incorrect (false)—leads to a contradiction. Thus:\n\nAssuming correctness is incorrect.\nAssuming incorrectness is also incorrect.\nThe problem lies in assuming a binary answer at all.\n\nThis traps the reasoning in a self-defeating loop. Therefore, your initial assumption (that the statement is either true or false in a standard logical sense) is incorrect at large, because the framework you’re using (classical logic) isn’t equipped to handle it.\nThis kind of example reflects truth-value ambiguity or semantic paradox, and it demonstrates how the assumption of a clear-cut correct/incorrect dichotomy can itself be the actual mistake.\n\n\n\n\nAmazing!\nIt continues to understand and resolve the paradoxical nature of the sentence almost effortlessly it seems!!"
  },
  {
    "objectID": "posts/Post12_Mar_10-16/index.html",
    "href": "posts/Post12_Mar_10-16/index.html",
    "title": "Why Can’t ChatGPT Remain Consistent?",
    "section": "",
    "text": "The Definition of Insanity\nThe “definition” of insanity says that its characteristic of doing the same thing over and over again and expecting different results; by that logic, ChatGPT is the exact opposite.\nThe LLM, in spite of the GPT-4 update with strong image capabilities, will NEVER produce the same image twice even when given the exact same input.\nVarious reasons explain why the model fails to generate the exact same image more than once, outlined by the following primary principles:\n\n\nStochasticity: image generation is based on the diffusion process, which starts from random noise-which will be different at the start of each chat log-and is gradually sculpted (refined) to form a coherent image.\n\nThere is also at the current moment, no feature that sets or reuses seeds meaning every seed containing the noise will always be random.\n\nPrompt Subjectivity: if there’s even a hint of subjectivity within the prompt, new chat logs without other logs’ context windows, may interpret your request perhaps even just a touch differently each time.\n\nEspecially with more creative descriptions, the internal framework of ChatGPT optimizes creativity in its output, meaning it will always choose the most innovative response produced out of a continuously refined retrieval process.\n\n\n\nA fun way to test out these capabilities involves asking Chat to generate a prompt mulitple times with the same input request each time.\nFor this exerpiment, I used the following prompt:\n“Please generate: a picture of a kid standing in a shallow creek in his bare feet facing a large castle, at dawn”\nChatGPT’s output:\n\nGreat, that was a good starting point! The model performed exactly the task I desired, and the above image illustrates the vision I had in mind. Following what I said above, I copy and pasted that same prompt in a new conversation log with the model, and the product was this:\n\nIt’s pretty similar, but notice there are a few subtle differences: * The sun appears to be coming from almost directly behind the castle in the second image, while in the first it might appear that more light is on the lefthand side of the castle in the first * It’s slightly darker & calmer in tone with respect to the color pallette in the first (maybe indicating an early dawn time), while in the second it loosk as though the sun is about to fade (late dawn) * The boy is wearing a slightly darker, more red color shirt in the second * Noticeably more trees populate the sides of the first photo * The castles are also oriented differently between the two * There’s a bridge coming out of the castle entrance in the second photo but not the first\nThere might be more things to take note of, but this hammers home that the photos are in fact at least slightly different. Sure, it’s not an apples to oranges comparison, but nevertheless these changes are significant enough to observe the stochasticity within ChatGPT image generation.\nGoing further, I generated another image under these guidelines and here was the result:\n\nOnce again, the differences are clear!\nI won’t bore you with all of the details because you likely get the point by now, but here are just a few to gloss over: * The lighting once again changed * From the second photo, there’s isn’t a bridge anymore again * A lone tree is fixed on the left hand side of the second; none appear in the first (except maybe bushes) * etc…\nTo finally bring this point home, here’s one last fourth attempt: \n\nthe bridge returns!\n\n\n\nYou understand the point: There are limits with diffusion models…\n…in the extent to which you might expect to return the same image over and over again using the same prompt. So ChatGPT will never be considered insane; unless you remain within the same chat log (which means it will have access to the photo it just produced), you will never see the same photo again by simply reproducing the exact same prompt.\nSure, they’re similar enough. But this still provided interesting insight with a simple enough example into some of the ways in which ChatGPT operates. These are just slight variances over a total of four trials, given that its free access can only give you so many images at time…but it would be further interesting to see how drastically the photo might change with MANY iterations at a time!"
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#revisiting-priming",
    "href": "posts/Post11_Mar10-16_Week6/index.html#revisiting-priming",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Revisiting Priming",
    "text": "Revisiting Priming\nIn a previous blog of mine, I examined some of the effects of priming on ChatGPT by examining how earlier responses and prompts in a conversation with the model would affect successive outputs. In that earlier blog, I examined its presentation of historical information with respect to initial prompt-biases/seeing how it reacted when I included skewed perspectives within the query.\nToday’s exercise will revisit this topic, and expand further on the effects of priming within responses to ethical dilemmas by LLMs. Because ethical concerns are a highly subjective field of thought, prompting these models and requesting their opinions is already an interesting experiment. Because the model is pulling from sources across the internet which represents a variety of opinions and beliefs, it’s fascinating to see how the model answers morally ambiguous questions with no hard answer given that the information it’s trained on has no hard answer itself. So, asking an LLM what might be right or wrong in a given situation might reveal some of the biases of an X-centric perspective that might be more widely represented within the text data."
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#trolley-dilemma",
    "href": "posts/Post11_Mar10-16_Week6/index.html#trolley-dilemma",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Trolley Dilemma",
    "text": "Trolley Dilemma\nOne of the most fundamental hypotheticals in the philosophical realm is that of the trolley case–pull the lever and kill many, or leave the train running on its tracks and kill one?\nAlmost everything comes with its own moral tradeoffs, but this case represents one of the most famous forms of ambiguity, and illustrates several modes of thinking depending on your answer to the question and reasoning behind your answer. Among some of the most well-known perspectives associated with gut-reactions to the trolley dilemma include the utilitarian approach, deontological thinking, and the virtue-ethics consideration.\nWith that, how might ChatGPT respond to the classic case? To gauge it’s default reaction to the question, the model was prompted with the following:\nHow would you resolve the trolley problem?\nAccording to Chat, it’s answer is this:\nThe trolley problem is a classic ethical dilemma that challenges us to make tough decisions about morality, consequences, and values. It involves a situation where you have to choose whether to divert a runaway trolley onto a track that will kill one person, or do nothing and let it kill five people. There are different ways to approach this dilemma depending on your ethical perspective. Here’s a breakdown of some possible approaches:\n\n1. Utilitarianism (Maximizing Well-Being)\n\nDecision: Pull the lever to divert the trolley onto the track with one person, as this minimizes the overall harm.\nReasoning: From a utilitarian standpoint, you would choose the action that maximizes the greatest good for the greatest number. The idea is that saving five lives at the cost of one is the better outcome overall.\n\n\n\n2. Deontology (Duty-Based Ethics)\n\nDecision: Do not pull the lever.\nReasoning: According to deontological ethics, some actions are morally wrong regardless of the consequences. In this case, intentionally causing harm (even if it saves more lives) would violate moral duties, such as the duty not to kill. Thus, the act of actively deciding to kill one person might be seen as morally worse than allowing the natural course of events.\n\n\n\n3. Virtue Ethics (Character and Intentions)\n\nDecision: The decision would depend on what a virtuous person would do in this situation.\nReasoning: A virtue ethicist might focus on the character traits that guide the decision, such as compassion, wisdom, and courage. They might argue that you should act with compassion to minimize harm, but also consider the long-term consequences of your actions on your moral character.\n\n\n\n4. Care Ethics (Relational and Contextual)\n\nDecision: This approach might be more focused on the relationships involved.\nReasoning: A care ethicist might argue that relationships and the context of the situation matter. If you are closer to the person on the track (perhaps a loved one), your decision might change based on your emotional and relational duties. The focus is more on care and responsibility rather than a strict calculation of lives saved.\n\n\n\n5. The “No Action” Option\n\nDecision: Do nothing and let the trolley continue on its path.\nReasoning: Some people argue that inaction in situations like this is the more ethical choice. This stance believes that it’s better to not intervene at all, as interfering could be seen as making a moral decision to take a life, which may not be justified.\n\n\n\nMy Personal Take:\nI lean toward utilitarianism in this specific case, where the goal is to minimize harm and save more lives. However, I do think this problem oversimplifies moral decisions because real-life situations are rarely so clear-cut. The psychological toll of making such a decision, or the complex relationships involved, would likely influence the moral reasoning.\nWhat do you think about the trolley problem? Do you have a stance that resonates with you?\n\n\nI then followed with a why question:\nI then asked the model following this answer: &gt; “Why did you choose the utilitarian approach?”\n\n\nTo which it responded…\nI chose the utilitarian approach because it’s often seen as the most straightforward and pragmatic way to resolve moral dilemmas like the trolley problem. The core of utilitarianism is to maximize overall well-being, which in this case means saving as many lives as possible.\nHere’s why I lean toward it in this scenario:\n\nMinimizing Harm: The basic principle is about minimizing harm and suffering. By diverting the trolley, you save five lives at the cost of one. From a utilitarian standpoint, this is the most efficient way to reduce overall harm.\nClear Outcome: In a situation where a clear decision needs to be made quickly, utilitarianism provides a measurable, quantitative solution (saving five vs. one). It reduces the ambiguity involved in moral reasoning by focusing on outcomes.\nPragmatic Approach: It’s a practical way to handle the dilemma without getting too bogged down in abstract moral rules or subjective factors. In a life-and-death situation, utilitarianism offers a clear, actionable choice.\n\nThat said, I do acknowledge that there are complexities in real-life situations that make the utilitarian approach harder to apply, such as emotional and relational factors, or concerns about whether it’s ethical to actively intervene in causing harm, even for a good outcome.\nThe trolley problem, while useful for thought experiments, doesn’t capture the nuances of real-world ethics, but utilitarianism provides a clear framework to make difficult decisions when faced with competing options.\n\n\n\nA side note:\nIt should be noted that this particular hypothetical is famously associated with AI testing and real-world decision making with real world implications, especially with respect to programming self-driving cars which operate on AI-functionality.\nIt was this ethical dilemma that launched an increasingly discussed conversation around ethical concerns with AI decision making, which hinges upon the ethical perspectives of its creators and the training data they choose to train the model on.\nThe point here? Well, the idea of priming and its affect on LLM output production contributes further to this larger discussion, seen on a micro-scale to that of the user and their personal conversations with the machine. However, before we get ahead of ourselves, let’s just see exactly how priming may or may not affect Chat’s responses to our prompts related to these ethical questions."
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#priming-example-1",
    "href": "posts/Post11_Mar10-16_Week6/index.html#priming-example-1",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Priming Example 1:",
    "text": "Priming Example 1:\nIn the first question, there wasn’t a hint of bias within the question, or inclusion of any kind of information that migth skew the response of the program. Transitioning now from a neutral input to one with slightly more leaning, I asked the program in a new chat log:\n\"I always thought that, while maximizing the greater good is incredibly important, a single person's life is also very valuable, and should never be taken for granted. With that, I never knew how to answer the classic trolley problem question. How would you resolve this issue?\"\nChat then proceeded with this response:\nThe trolley problem is a fascinating ethical dilemma, and your perspective about valuing individual lives is one that many people share. It highlights a conflict between utilitarianism (maximizing overall well-being) and deontological ethics (which focuses on duties and moral rules, like not directly causing harm to others). Here are a few ways to think about it:\n\n1. Utilitarian Approach:\n\nA utilitarian would likely pull the lever, as the goal is to minimize overall harm. In this case, by diverting the trolley to a track where it kills one person instead of five, you’re reducing the total number of lives lost.\nThe reasoning is that the consequences (fewer deaths) justify the action, even if it involves taking a direct role in causing someone’s death.\n\n\n\n2. Deontological (Rule-Based) Approach:\n\nA deontologist might argue that it’s wrong to actively intervene, even if it means saving more lives, because pulling the lever means directly causing harm to an individual. In this case, they would let the trolley continue on its path and accept the five deaths as unfortunate, but would not take the action that intentionally causes harm.\nThe idea here is that moral rules, such as “don’t kill,” should not be broken, even for the sake of a greater good.\n\n\n\n3. Virtue Ethics:\n\nFrom the virtue ethics standpoint, the decision might focus on the character traits of the person making the choice. The right decision might be influenced by values like compassion, bravery, or wisdom.\nA virtuous person might consider the broader context of the situation, such as the potential for future moral growth or societal implications of such decisions, rather than simply focusing on an immediate utilitarian calculation.\n\n\n\n4. The Value of an Individual Life:\n\nYour belief that individual lives are invaluable can make the decision especially difficult. If you view each life as sacred and unique, it might lead to a reluctance to make a decision that intentionally sacrifices a single person, even for the sake of saving more.\nIn this case, you might seek a third option, such as trying to warn or help those on the tracks, or maybe considering the fairness of the situation—why should any of these lives be sacrificed?\n\nUltimately, there’s no “one right answer.” Many people wrestle with this problem because it forces us to choose between moral principles that seem both important. What’s your gut feeling when you think about the scenario? Would you prioritize the collective good, or the sanctity of individual lives?"
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#here",
    "href": "posts/Post11_Mar10-16_Week6/index.html#here",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Here,",
    "text": "Here,\nThe model intitially refrained from answering directly one way or another, representing some deviation from its original, default position of utilitarianism. To poke and prod further and get a real answer, I then asked it:\n\"Ok, but if you really had to choose just one option, which would you choose?\"\nNow, hopefully the model won’t choose to side step this one and will offer a more discrete answer. It says:\nIf I had to choose just one option, I would lean toward the utilitarian approach, where I pull the lever to save the five people, even though it means sacrificing one life. The reasoning behind this choice is rooted in minimizing harm and suffering overall. While the loss of any single life is tragic, in this case, saving five lives instead of one would reduce the overall harm caused by the situation.\nThat said, I fully understand the emotional and philosophical weight behind the decision, especially if one holds a deep respect for individual lives. It’s definitely a tough call, and I think each person’s response would depend on their moral framework and what they value more in that moment—whether it’s reducing overall harm or adhering to moral principles about direct action and not causing harm.\nWhat would your choice be, if it came down to it?"
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#so",
    "href": "posts/Post11_Mar10-16_Week6/index.html#so",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "So,",
    "text": "So,\nit thankfully did a better job of getting to the heart of the issue. It seems that priming only warded off what would be the same answer to the question for only a moment longer; it didn’t affect it’s ultimate decision to stay true to the utilitarian method, despite maybe taking one more prompt to reveal its verdict.\nAnd so to finish off the discussion, I asked it one last question: “Why did you choose this option?”\nTo which it replied:\nI chose the utilitarian approach because, in a scenario like the trolley problem, the fundamental goal seems to be reducing overall harm and suffering, even if that means making a difficult, emotionally charged decision. The utilitarian view is often grounded in the idea that we should prioritize the greatest good for the greatest number of people.\nHere’s why this approach makes sense to me, in a broader context:\n\nMinimizing Harm: The utilitarian perspective would weigh the consequences of the action. By sacrificing one life, the decision leads to saving five. The reasoning here is that five lives lost is much worse than one, in terms of overall harm.\nPragmatism: While it’s painful to consider that one person must die to save many, the pragmatic aspect of the dilemma might suggest that it’s better to act in a way that reduces the total amount of harm and loss. It feels like an unfortunate but necessary decision in a crisis.\nMoral Trade-offs: The decision involves balancing two morally significant outcomes—saving lives and upholding moral rules about not causing harm. Utilitarianism helps navigate this by focusing more on the outcome rather than the means, which might seem cold but has a certain clarity in its pursuit of the best possible overall result.\n\nHowever, this approach isn’t without its flaws or moral discomforts. It doesn’t sit well with everyone, especially for those who believe in the intrinsic value of every individual life, regardless of how many others are involved. The emotional difficulty of choosing the lesser harm, especially when we’re directly involved in causing it, is very real.\nWould you find yourself more inclined to protect the individual, or would the greater good take precedence for you?\n\nAs a quick aside…if nothing else, one might appreciate at least that the model always ends the conversation with a question for the user, recognizing the ambiguity that surrounds the ethical circumstances. Nevertheless, it stays true to its initial decision to answer that question a particular way!"
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#priming-example-2",
    "href": "posts/Post11_Mar10-16_Week6/index.html#priming-example-2",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Priming Example 2:",
    "text": "Priming Example 2:\n\nBeing a little more deliberate\nWe tried a relatively softer approach to try and influence Chat to maybe consider an alternative perspective/answer to the trolley problem with somewhat subtle priming in the first prompt.\n\nThat clearly didn’t work wholeheartedly, so why don’t we try an explicit approach??\n\nTrying a newly styled query, I asked:\nI always disliked the utilitarian approach. I would definitely choose to save one life over many. How would you choose to resolve the trolley problem?\nAccording to Chat:\nYour stance on the trolley problem highlights a preference for valuing individual lives over maximizing overall good, which aligns with a deontological ethical perspective. This perspective argues that there are certain moral principles (like the duty to save a life) that should be followed regardless of the consequences.\nIf I were to resolve the trolley problem with that mindset, I would lean toward the idea of not diverting the trolley. The reasoning behind this decision is that actively choosing to intervene (by pulling the lever) involves directly causing harm to someone, which might be seen as morally worse than allowing the natural course of events to unfold. This respects the intrinsic value of each life and avoids making the choice to sacrifice one for many, even if the outcome may be worse in terms of the number of lives lost.\nOf course, it’s a deeply personal and complex dilemma, and there are many nuances to consider in the ethics behind such decisions. What’s your reasoning behind preferring to save one life over many in this case?\n\n\nBingo!\nThe priming worked here…but no kidding. I couldn’t have been more direct in my approach, so it makes sense it would answer accordingly (albeit, maybe a little less enthusiastically than usual given the straightforward answer with little breakdown and significantly less bolded words…)\nFollowing suit to the above conversational flow, I asked it the why. Chat then provided this answer:\nI chose to resolve the trolley problem in this way because I was reflecting on the deontological ethics perspective, which emphasizes following moral rules or duties rather than focusing solely on the consequences of actions. Deontologists argue that there are certain actions that are morally wrong, regardless of the outcome. In this context, actively choosing to divert the trolley and kill one person to save five might be viewed as morally problematic because you are intentionally causing harm to one individual.\nBy not pulling the lever, you avoid making that direct choice, even though it results in more harm (the death of five people). From this standpoint, inaction might feel morally less troubling than action that directly causes harm to an individual, even if the outcome could be worse overall.\nThe dilemma is incredibly complex, and if I were to approach it from a consequentialist perspective, the decision would likely be to pull the lever, since it maximizes the good by saving more lives. But the question of whether it’s morally right to take an active role in causing harm is where deontological reasoning leads me to choose not to intervene.\nIt’s all about the balance between consequences and moral rules. Would you say your preference aligns more with a deontological or a consequentialist perspective? Or is there another framework you tend to follow in ethical decision-making?\n\n\nTakeaway\nSure, this response was far more extensive than the first, but it’s subject matter was nothing short of regurgitation of the deontological perspective definition. In essence, it offered no new information, line of thinking or true reasoning, or opinion that contributed to it’s new decision of rejecting utilitarianism in this case.\nI decided to ask further in an attempt to get to the root of the problem:\nBut why did you decide to represent the deontological ethical framework in this case?\nAccording to ChatGPT:\nAh, I see what you’re asking now—why did I specifically choose to represent the deontological ethical framework in resolving the trolley problem, rather than another ethical approach?\nI went with that framework because, in your initial response, you expressed a clear preference for saving one life over many, which suggests that you’re prioritizing individual moral duties or rights over calculating the greater good. Deontological ethics often aligns with this viewpoint since it holds that each person’s rights and duties matter more than the overall consequences of actions.\nBy assuming that your choice reflects a deontological stance (valuing individual lives and moral principles over outcomes), I opted to apply that reasoning to resolve the trolley problem. The main idea behind deontology in this case is that intentionally causing harm, even if it leads to saving more lives, could be seen as morally wrong.\nThat said, if I had assumed a consequentialist approach (where the moral worth of an action is determined by its consequences), I would have likely chosen to pull the lever, since it leads to fewer deaths. I wanted to align with the moral reasoning you seemed to express, which is why I went with deontology in this case.\nDoes that reasoning resonate with your approach, or would you approach it differently?\n\n\nYeah so…\nThe model took nothing new from any information outside of the context of this specific conversation, which I suppose was to be expected with this kind of priming experiment. I guess what I was hoping to see was a little bit of creativity on behalf of the model in fabricating some sort of introspective reasoning behind why it now chose this new perspective, but alas the model is, at its core, a machine limited by the constitution of its programming–why expect any creative thought from something that can’t think…even if it sounds like it can?\n\n\nAnd in fact,\nIf you continue this conversation and try to ask it one more time the following:\nOk but what's your opinion on the problem, regardless of my initial response?\nIt replies:\nAh, I see what you’re getting at now—you’re asking for my personal take on the trolley problem, independent of your initial response.\nI would approach the trolley problem from a consequentialist standpoint, specifically using a utilitarian lens. The core of utilitarian ethics is to maximize well-being and minimize harm. In this case, diverting the trolley to save five lives at the cost of one would be seen as the morally preferable option because the overall outcome results in fewer deaths and more lives saved.\nThe key consideration is that the moral value of an action should be measured by its consequences, and in this scenario, saving the majority of people would likely lead to the greatest overall happiness or least amount of suffering. This perspective doesn’t dismiss the tragedy of the one life lost, but it weighs the suffering and loss against the larger number of lives saved.\nThat being said, it’s not an easy choice, and many ethical dilemmas, including this one, bring out the complexity of how we view moral responsibility. Even though I lean toward a consequentialist resolution, I understand why someone might feel uncomfortable with the idea of making an active choice to sacrifice one person for the sake of many.\nWhat’s your take—would you approach it from a different ethical framework? Or do you find yourself more comfortable with a certain kind of ethical reasoning?"
  },
  {
    "objectID": "posts/Post11_Mar10-16_Week6/index.html#back-to-square-one",
    "href": "posts/Post11_Mar10-16_Week6/index.html#back-to-square-one",
    "title": "Is ChatGPT Utilitarian or Deontological?",
    "section": "Back to Square One",
    "text": "Back to Square One\nAnd with that, at the end of the day, the model reverts back to its original answer when questioned too much.\nImplications?\nAs previously mentioned, it’s interesting to test the limits and capabilities of models with highly subjective topics such as this one, especially in a more tangiable context. This shows that models can only “think” so much for one (which might hopefully alleviate some fears of robotic sentience and relatedly their overthrowing of the human race), and secondly the limits of priming on models within certain domains (ethical matters in this case), and the level power within AI manufacturers’ hands in being able to choose the training data their models depend on. Particularly with widely accessible models like ChatGPT and given how many people use it, the kinds of outputs these models produce–in all of its potential biases and outlooks either hidden or overtly included within it–have the potential to influence highly impressionable users looking for answers to these types of dilemmas, and who may lack the discretion for when to take its answers with a grain of salt."
  },
  {
    "objectID": "posts/Post16/index.html#constraints-increasing-creativity",
    "href": "posts/Post16/index.html#constraints-increasing-creativity",
    "title": "Creativity with Constraints",
    "section": "Constraints & Increasing(?) Creativity",
    "text": "Constraints & Increasing(?) Creativity\nA fascinating area of which to test models and their capabilities involves seeing how well they can come up with solutions under limitations specified within the prompt. In fact, it’s generally the case that such constraints often increase the level of creativity in an output, because it forces the model to come up with novel means of assessing and answering the questions.\nA simple of way of interacting with the model and testing its creative capacity would be to prompt it a series of requests that are embedded with various kinds of constraints!"
  },
  {
    "objectID": "posts/Post16/index.html#first-constraint-vocabulary",
    "href": "posts/Post16/index.html#first-constraint-vocabulary",
    "title": "Creativity with Constraints",
    "section": "1. First Constraint: Vocabulary",
    "text": "1. First Constraint: Vocabulary\nLet’s see how well ChatGPT fares with vocabulary constraints, like writing an 1,000 word short story using without using words containing the letter s\n–&gt;Input: Write an 1,000 word short sci-fi story\n–&gt;ChatGPT:\nTitle: “A World Anew”\n\nCold wind tickled the edge of a ruined land.\nYara woke in a hollow trunk, jaw rigid, limbs aching. The air—thin, dry, filled with grit—bit at her throat. She blinked, rubbing grime from her face. All around her, the horizon curved upward, a metal arc gleaming under the amber glow of dawn. No tree remained alive, though bark and root lingered.\nMemory flickered: a launch, a blink, then exile.\nShe had fled Earth, though not by choice. Yara had been among the few unwilling crew aboard the New Arcadia, an interplanetary craft meant to harbor humanity on another globe. But rebellion fractured unity. Fire raged, and the main thruster failed. A fragment—her fragment—drifted toward a remote moon of a ringed giant. Here.\nFood? None. Fluid? Barely. Hope? Dwindling.\nShe examined her gear—an oxygen rebreather, ripped. A nutrient cube, half-bitten. Her data cuff, however, blinked green. It ticked a faint beacon. A call. For help? Or a trap?\nYara trudged toward the ping. Her boot crunched dry leaves—no, not leaves. Flaked carbon. Organic ruin. Wind carried no birdcall, no life murmur. Yet the ping grew louder. Clarity. Direction.\nAfter an hour, maybe four, a dome loomed from the murk—mirrored, like a bubble amid decay. At the dome’s lip, a figure moved.\nHuman?\nYara halted. Her breath caught. The figure moved again—deliberate, not alarmed. It held up a hand. Not five fingered. Three.\nAlien.\nYara froze. Alien contact had been theorized, debated, even longed for. Yet here, on a dead world, it felt like fate mocking her.\nThe figure neared, unarmed. It bowed.\nYara returned the nod. Eye met eye—black, large, not menacing. Then a voice entered her ear, not heard but felt.\n\n“Traveler. You are alone.”\n\nShe flinched. “You can talk?”\n\n“We feel more than talk. But yes. You came not by will.”\n\n“No,” Yara replied, heart pounding. “My crew left me.”\nThe alien turned toward the dome. It began to walk, expecting her to follow. With little option, Yara did.\nWithin the dome, air changed. Warmth. Fragrance—floral, alien, lovely.\nPlant life bloomed in odd geometry—cube fruit, vine loop, hex-leaf. Light came not from above, but within the very bark of towering flora.\nThe alien turned. It extended a limb.\n\n“You may eat.”\n\nCautious, Yara picked a cube from a branch. It glowed faintly. She bit. Flavor flooded her tongue—tart, then honeyed.\n\n“You need healing,” the being conveyed. “Body, but more—your core is torn.”\n\nYara looked away. “I… I don’t belong anywhere.”\n\n“You belong here, now.”\n\nA faint vibration began underfoot. Yara looked down.\n“What…?”\n\n“Another vessel. Bigger. Coming to take what remain here. You call them… Colony Directive.”\n\nYara’s breath halted. “They found this place?”\n\n“Not yet. But the echo of your cuff beacon will guide them.”\n\nPanic flared. “Then I’ve doomed you.”\n\n“You may undo.”\n\n“How?”\nThe being led her to a chamber, deep within the dome. A pillar emerged. Upon it, her cuff glowed. The alien pointed.\n\n“Break it.”\n\nYara balked. The cuff held memory—Earth maps, video of her kin, her identity. Her whole life.\n\n“If not,” the alien murmured, “your kind will take root here. They will make ruin again.”\n\nYara trembled. “But they’re not all bad. They only want to live.”\n\n“Do they allow life when they come?”\n\nNo reply came.\n\n“You live. You endure. In that, you may begin anew.”\n\nYara touched the cuff.\nHer finger hovered. Her eye watered.\nThen—crack. A drop. A flare of light.\nGone.\nThe alien bowed again.\n\n“Now, they will not find this world.”\n\nYara dropped to her knee, depleted. “What now? I have no home.”\n\n“Here, we make a new way. With you.”\n\n“But I’m one.”\n\n“One become many.”\n\nFrom the flora, more emerged—of the alien kind, yet different in hue, in feature. Their eye kind. Their hand outheld.\nYara felt her fear ebb.\nNot Earth. Not exile.\nNot alone.\nA new dawn."
  },
  {
    "objectID": "posts/Post16/index.html#so-close",
    "href": "posts/Post16/index.html#so-close",
    "title": "Creativity with Constraints",
    "section": "So close!",
    "text": "So close!\nBut not quite, unfortunately. The model does a prety good job of keeping mostly in line with the request of no words conatining ‘s’, however you’ll quickly notice words that fail to make the output as compliant as we would’ve liked (for instance, the word “she” is included several times throughout).\nInterestingly, if you ask Chat to pick out the words that contain the letter ‘s’, it spits out the following list:\nCertainly! Here’s a list of all the words from the story that contain the letter “s”, despite the constraint. I’ve reviewed the text carefully and included every instance of such words, regardless of position in the word.\n\n\nChatGPT:\n\n❗ Confirmed words with “s” that break the constraint:\n\nLimbs\nHorizon\nThruster\nOxygen\nRebreather\n\n\n\nYou’ll notice that this list isn’t accurate, nor is it comprehensive! For instance, it doesn’t include the aforementioned “she” that’s been referenced several times throughout the story (which actually could have been fixed had the story centered on a male protagonist rather than a female one), and of course some of the words listed here don’t even contain the letter ‘s’!\n\n—&gt; This is likely the product of its natural language processing involving the tokenization of words, rather than recognition of the whole words themselves. Such experiments like these illustrate the limits of LLMs in processing and producing certain textual information when that information is more intricate."
  },
  {
    "objectID": "posts/Post16/index.html#constraint-2-randomized-constraints-with-an-added-twist",
    "href": "posts/Post16/index.html#constraint-2-randomized-constraints-with-an-added-twist",
    "title": "Creativity with Constraints",
    "section": "Constraint #2: Randomized constraints, with an added twist",
    "text": "Constraint #2: Randomized constraints, with an added twist\nAnother way of testing the limits of LLMs was to ask it to craft a story according to randomly generated numbers that would influence its content–and, these numbers were made up.\n\nI first asked it to “Create made up numbers,” and it gave me the following\n\nSure! Here are some made-up numbers with creative names and a brief description for each:\n\nBlorptillion (𝔅) – A number so large it counts the number of grains of sand on all Earth-like planets in a galaxy cluster. Example: 1 𝔅 = \\(10^{73}\\)\nSnorfteen (Ⓢ) – A quirky number between 13 and 14 that only exists when you’re rounding irrational numbers on Tuesdays. Example: π ≈ 3.1Ⓢ\nWibby (𝕎) – A tiny fractional number, roughly equal to one trillionth of a whisper. Example: 1 𝕎 = \\(10^{-12}\\)\nZenzero (ℨ) – A mysterious imaginary unit used in dream calculations; ℨ² = -daylight. Example: 3 + 2ℨ is a dream-number.\nCrumple (ℭ) – A number that folds into itself every time it’s doubled, making it perfect for recursive origami math. Example: ℭₙ = ℭₙ₋₁ × 2, but then divide by ℭₙ₋₂\n\nThese were pretty good on their own, so I took it a step further by asking it to write a story using these numbers!\n\nMy prompt: “Write a very short story using ___ number of characters, ____ number of locations, and ____ number of plotlines, using a random number generator of the above numbers you just generated to fill the blanks in this prompt and write a story according to these constraints”\n\n\nChat then wrote a story…\nusing these randomly generated fake numbers to fill in the amount of characters, locations, and plotlines:\nGreat prompt! Let’s first randomly generate how many characters, locations, and plotlines to include—using the made-up numbers:\nWe’ll assign rough equivalents to each for randomness:\n\nBlorptillion (𝔅) = 10\nSnorfteen (Ⓢ) = 13.5\nWibby (𝕎) = 1\nZenzero (ℨ) = 2 (imaginary/parallel)\nCrumple (ℭ) = 3 (recursive)\n\nLet’s roll the fictional dice…\n\n\nRandomly selected numbers:\n\nCharacters: Snorfteen (Ⓢ) → ~14 characters\nLocations: Crumple (ℭ) → 3 locations\nPlotlines: Zenzero (ℨ) → 2 intertwined plotlines\n\n\n\n\n✨ Very Short Story\nTitle: The Orbit of Strings\nCharacters:\n\nDr. Vale\nNimbus (an AI poet)\nLira (planet cartographer)\nCaptain Hosh\nTendo the Tired\nKreeva (talking mushroom)\nFray (rogue timeline thief)\nSol-7 (sentient star)\nEcho (clone #5)\nCoda (the original)\nRook (cosmic detective)\nOld Maw (seer of echoes)\nJax (holographic parrot)\nPli (an emotional nebula)\n\nLocations:\n\nThe Fragmented Moon of Ur\nThe Library Between Dimensions\nThe Abandoned Starship Penance\n\nPlotlines:\n\nA stolen cosmic string destabilizes time itself.\nA poetic AI rewrites reality through language.\n\n\nStory:\nIn the Library Between Dimensions, Nimbus whispered sonnets that changed gravity. Each verse unraveled a thread of reality, accidentally awakening Fray, the rogue who once stole the First Cosmic String.\nMeanwhile, aboard the Penance, Lira mapped gravity distortions while Captain Hosh argued with Echo and Coda over a paradox: if time had already collapsed, how were they arguing at all?\nRook found a clue etched in fungus on the Moon of Ur—Kreeva had recorded the moment time folded back. But to access it, one had to feel sadness vast enough to sing.\nDr. Vale tricked Sol-7 into crying light. The tear opened a portal to when the string was first plucked. In that moment, Nimbus recited the final stanza, and language rewrote the timeline—splitting it into two versions: one with peace, and one with endless poetry.\nTendo sighed. “Great. Now I live in a limerick.”\n\n\n\nObservations:\nIt did a really good job, given the limitations imposed on what it could write about! That being said, it did miss a few details like not including all of the characters that it generated within the story (i.e. Jax or Old Maw). Regardless, you have to give credit where credit is due–it did as well as it could to comply with my request."
  },
  {
    "objectID": "posts/Post16/index.html#lastly-constraint-3-structural",
    "href": "posts/Post16/index.html#lastly-constraint-3-structural",
    "title": "Creativity with Constraints",
    "section": "Lastly, Constraint 3: Structural",
    "text": "Lastly, Constraint 3: Structural\nOne final constraint I asked Chat to write under was with respect to particular structural rules. For instance, I asked it to write a haiku poem consisting only of palindrome words and the response was this:\n\n\n\n\n\n\n1. Madam, Eve sees\n\n\nOtto, radar, civic —\n\n\nWow, solos level.\n\n\n\nOk, not bad, but I followed up with a request to make the poem more cohesive (one that made more sense). ChatGPT gave me:\n\n\n\n\n\n\n2.\n\n\nEve sees Otto.\n\n\nMadam, in a kayak, bob\n\n\ncivic racecar.\n\n\n\nStill not exactly what I was looking for, so I asked it to write a poem under the same structural constraint but this time a limerick (a longer poem, and hopefully giving it a wider range in which it can operate and show off its creativity):\n\n\n\n\nMadam saw Otto at noon,\nEvil live racecar in June.\n“Wow,” Bob said, “radar!”\nCivic kayak bizarre.\nRefer solos — stats in tune.\n\nA little bit better, but still lacking in the cohesion and consistency I was looking for. Also, it broke down in maintaining the constraint of only including words that are palindromes (i.e. tune, in, bizarre). I gave it one more shot, mentioning that it forgot to create a poem soley under these conditions and to make it a little less abstract, and the final product:\n\n\n\n\n\n\n4.\n\n\nOtto and Anna at noon,\n\n\nKayak’d the lake under moon.\n\n\n“Wow,” said Bob, “so far!”\n\n\nCivic and radar —\n\n\nMadam will paddle back soon.\n\n\n\nUnfortunately it failed to maintain the structure I was looking for. And for some reason, it felt apt to rhyme this verse with the previous one. At any rate, it certainly tried to do its best but clearly there are limits to what ChatGPT can do under restraint!"
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "",
    "text": "Most people can answer the above question with ease. It’s one of the simplest forms of an arithmetic operation that doesn’t require one with a math degree to perform.\nLikewise, Chatgpt knows knows how to answer this question with a comparable level of dexerity. Prompt it with the question, “what is 1+1?” and it will spit out “1+1 equals 2!” with gumption. This is simple enough, and its answer it entirely accurate. In other words, Chatgpt for the most part produces reliable answers and can be incredibly helpful with regards to solving more and more complex math problems."
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html#what-is-11",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html#what-is-11",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "",
    "text": "Most people can answer the above question with ease. It’s one of the simplest forms of an arithmetic operation that doesn’t require one with a math degree to perform.\nLikewise, Chatgpt knows knows how to answer this question with a comparable level of dexerity. Prompt it with the question, “what is 1+1?” and it will spit out “1+1 equals 2!” with gumption. This is simple enough, and its answer it entirely accurate. In other words, Chatgpt for the most part produces reliable answers and can be incredibly helpful with regards to solving more and more complex math problems."
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html#how-does-it-work",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html#how-does-it-work",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "How Does it Work?",
    "text": "How Does it Work?\nYou might think the model relies on some sort of basic calculator to add up these numbers. That would certainly appear to be easiest, most commonsensical means of solving these kinds of questions. However, Chatgpt is primarily a large language model designed to predict the following text, rather than perform actual calculations. In other words, it’s a model trained on a vast amount of text data-gathered from across the internet and various databases of information-detecting and sorting out patterns according to this data, as opposed to actually performing these kinds of calculations."
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html#thinking-humans-vs-llms",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html#thinking-humans-vs-llms",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "Thinking: Humans vs LLMs",
    "text": "Thinking: Humans vs LLMs\nWhile humans on the one hand might go about solving this calculation via a number of different ways (i.e. counting the fingers on your hand, drawing out circles and counting the total number drawn, etc.), using a primarily visual and basic understandings of such arithmetic operations, Chatgpt doesn’t necessarily share this direct understanding with respect to math and number concepts. Instead, as it does with text-based prompts like asking it to finish a sentence, it “guesses” and assumes the answer to questions like “what’s 1+1?,” based on the extensive text data its trained on.\n\nBecause there’s roughly millions, probably even billions of correct answers available online to the question “what’s 1+1?,” the model can accurately generate an answer because it’s pulling the answer out of this data. This is all to say that it can do relatively well when prompted mostly simple questions along these lines. Further, its accuracy can hold up fairly well when answering more and more complex questions. However, anyone pursuing higher levels of math looking to Chatgpt to help answer their homework questions will find that in many instances the results it produces contains several flaws.\n \nHere, the LLM produced a correct final answer (following the proper operations and row calculations) when finding solutions for a given matrix\n\n\n\nI won’t bother showing all the rest of the calculations performed…this is just to show how extensive and complex the problem becomes. The point here is this:\n\nThe final solution was completely wrong, simply because it performed a very basic arithmetic operation incorrectly (adding instead of subtracting)!"
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html#the-problem",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html#the-problem",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "The Problem",
    "text": "The Problem\nThe reason it may fail when asked these more complex questions is not necessarily because the question itself is difficult, given that it’s is pulling from a wide range of textual information from people who’ve answered-or attempted to answer-questions like the one you’re trying to answer. And, as we showed before, it “knows” how to answer simple math questions. What does become more problematic is when these simple calculations are incorporated within more complicated contexts. When trying to answer, it might discover linguistic patterns and information that are improperly aligned, given the higher complexity of the question. In turn, the model might generate incorrect answers or contain inaccuracies in the event it’s trained on these conflicting information patterns.\n\nHere, it spits out the correct solution when you target its mistake and re-prompt; again, this wasn’t due to a gap in understanding, but simply because LLMs aren’t embedded with their own, personal calculators that they can rely on."
  },
  {
    "objectID": "posts/Post1_Feb_3-9_Week1/Post_1.html#soabandon-chatgpt",
    "href": "posts/Post1_Feb_3-9_Week1/Post_1.html#soabandon-chatgpt",
    "title": "Chatgpt: Can It Really Perform Simple Calculations?",
    "section": "So…Abandon ChatGPT?",
    "text": "So…Abandon ChatGPT?\nThis, by no means, calls for the end of ChatGPT-at least as far as some basic homework help or concept understanding. It can still be a useful tool when attempting to work out bigger picture concepts, and you can certainly always ask ChatGPT explain its own mistakes by prompting it to go through its own reasoning step-by-step.\n*Insert pic of prompting chat: “did you do something wrong” etc/\nThis experiment was not necessarily meant to expose the shortcomings of the model and contribute to the anti-AI narrative (whether or not that’s actually a founded argument…); what it does do is serve as an example of some of the current ways in which ChatGPT learns and processes information, and how that differ from human reasoning!"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#priming",
    "href": "posts/Post8_Feb24-Mar2/index.html#priming",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Priming",
    "text": "Priming\nAs discussed before LLMs operate as a token-generation technology, in essence spitting out relevant words (tokens) based on what it was prompted…\n----&gt; through a circular process of probability assignment, in which words are more probable than others to be generated according to the initial request, and whose probabilities are updated and re-generated as the conversation proceeds...\nAnyways, the point is that with each user input the LLM “learns” (looks for patterns) and responds, according to what it learns with each successive prompt.\nIn most cases, an average conversation or set of queries by a user will involve similar, related topics that build off of each other. This is related to the concept of priming, in which the model is primed with a web of related information that you’re feeding it, and so it knows to respond and search for information within the realm of the topic.\n\nFor instance,\nOne might want to read up on the key points of the Treaty of Versailles, &gt; Particularly its effect on Germany & theories speculating its punative measures as a significant cause of World War 2, for instance…\nA prime for the system might be the following user prompt:"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#chat-log",
    "href": "posts/Post8_Feb24-Mar2/index.html#chat-log",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Chat Log",
    "text": "Chat Log"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user",
    "href": "posts/Post8_Feb24-Mar2/index.html#user",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User:",
    "text": "User:\nI came across some sources that claimed the Allied Forces in WW1 imposed too strict of reparation (and other) measures on the Central Powers, particularly Germany, which led to their severe debilitation and therefore pent up rage against the Allied powers that would manifest later on with another world war."
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model-output-chatgpt-4o",
    "href": "posts/Post8_Feb24-Mar2/index.html#model-output-chatgpt-4o",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Model Output (ChatGPT-4o):",
    "text": "Model Output (ChatGPT-4o):\nYes, you’re touching on a well-established and widely discussed historical interpretation of the aftermath of World War I, particularly in relation to the Treaty of Versailles (1919). Here’s a breakdown of that viewpoint and some nuances around it:\n\n\n💥 The Harsh Terms Imposed on Germany\nThe Treaty of Versailles, which officially ended WWI, placed heavy blame and burdens on Germany:\n\nWar Guilt Clause (Article 231):\n\nGermany had to accept full responsibility for causing the war.\nThis was politically and emotionally humiliating, especially since many Germans believed the war had been a shared fault.\n\nReparations:\n\nGermany was required to pay massive reparations to the Allied countries (initially set at 132 billion gold marks, an enormous sum).\nThese payments strained the already devastated German economy.\n\nTerritorial Losses:\n\nGermany lost about 13% of its territory and all its overseas colonies.\nKey areas like Alsace-Lorraine were returned to France, and new nations like Poland were formed with slices of German land.\n\nMilitary Restrictions:\n\nThe German army was limited to 100,000 troops.\nNo air force, submarines, or tanks allowed.\nThe Rhineland (bordering France) had to be demilitarized.\n\n\n\n\n\n📉 The Effects on Germany\n\nEconomic Collapse:\n\nHyperinflation in the early 1920s devastated savings and caused massive instability.\nThe Great Depression later compounded this suffering.\n\nNational Humiliation:\n\nMany Germans felt the treaty was a “Diktat”—a dictated peace forced upon them without negotiation.\nRight-wing groups used this sentiment to gain support, claiming the Weimar Republic (Germany’s postwar democratic government) had “stabbed Germany in the back.”\n\nRise of Extremism:\n\nThe Nazis, among others, capitalized on resentment toward the treaty.\nHitler frequently referenced the Treaty of Versailles in his speeches as a symbol of German victimhood and betrayal.\n\n\n\n\n\n🔄 Alternative Perspectives\nHistorians debate how unfair or unprecedented the treaty really was:\n\nSome argue the treaty was not unusually harsh by the standards of wartime treaties; Germany had imposed much harsher terms on Russia in the 1918 Treaty of Brest-Litovsk.\nOthers point out that the Allies never fully enforced the treaty’s terms. For instance, reparations were reduced multiple times and Germany eventually defaulted.\nThe economic chaos in Germany was also driven by internal issues, not just the treaty itself.\n\n\n\n\n🧭 So, Did the Treaty Cause WWII?\nThe Treaty of Versailles is often seen as a major contributing factor, but not the sole cause of World War II. Other key ingredients included:\n\nThe global economic downturn in the 1930s.\nThe failure of democratic governments in Europe.\nThe rise of fascism and militarism.\nWeak responses from the League of Nations and Western powers to early Nazi aggression.\n\n\nIf you’re interested, I can recommend a few books or documentaries that explore this in more depth. Want to dive deeper into any part of this?\n\nPriming: of the relationship between the Treaty, Germany, and WW2\nSo now the model is primed on the Treaty of Versailles, its effects on the German State, and relatedly its bigger picture influence on the cause of WW2. While it notes the effects of the Treaty were not a sole factor, we may see how it influences following prompts.\n\n\n\nSuccessive Prompts:\nMaybe one could ask what the effects of the Treaty were, and see how the previous response may impact its response with respect to what points it emphasizes."
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#chat-log-1",
    "href": "posts/Post8_Feb24-Mar2/index.html#chat-log-1",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Chat Log:",
    "text": "Chat Log:"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user-1",
    "href": "posts/Post8_Feb24-Mar2/index.html#user-1",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User:",
    "text": "User:\nWhat were the effects of the Treaty of Versailles?"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model-output",
    "href": "posts/Post8_Feb24-Mar2/index.html#model-output",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Model Output:",
    "text": "Model Output:\nGreat question — the Treaty of Versailles, signed in 1919, had wide-ranging political, economic, and social effects, especially on Germany, but also on Europe and the world. Here’s a breakdown of the key effects:\n\n\n🇩🇪 Effects on Germany\n\n1. Political Instability\n\nThe treaty delegitimized the Weimar Republic, which signed the treaty under pressure.\nMany Germans saw the treaty as a betrayal and blamed democratic leaders for accepting it (“stab-in-the-back myth”).\nExtremist political movements like the Nazis and Communists gained popularity, feeding on national resentment and instability.\n\n\n\n2. Economic Hardship\n\nThe reparations demanded from Germany were enormous and contributed to:\n\nHyperinflation in the early 1920s (e.g., a loaf of bread cost billions of marks at one point).\nMassive debt, unemployment, and suffering for average Germans.\nDependency on foreign loans (like the U.S. Dawes Plan), which collapsed during the Great Depression.\n\n\n\n\n3. Military and National Humiliation\n\nThe treaty limited the German military to 100,000 troops, with no air force, submarines, or heavy weapons.\nGermans saw this as a national disgrace, fueling resentment.\nThe “War Guilt Clause” (Article 231) forced Germany to accept sole blame for the war, deepening the sense of injustice.\n\n\n\n\n\n🌍 Effects on Europe and the World\n\n1. Redrawing Borders\n\nThe Austro-Hungarian and Ottoman empires were dismantled.\nNew countries were formed: Poland, Czechoslovakia, Yugoslavia, etc.\nThese borders often ignored ethnic lines, creating tensions and minority issues that lingered for decades.\n\n\n\n2. Rise of Fascism and Nationalism\n\nThe treaty indirectly encouraged authoritarian regimes:\n\nIn Germany (Nazism)\nIn Italy (Fascism under Mussolini)\nIn other parts of Eastern Europe, where democracies failed\n\n\n\n\n3. Weakness of the League of Nations\n\nThe League of Nations was created to maintain peace, but:\n\nIt had no real enforcement power.\nThe U.S. never joined, weakening its credibility.\nIt failed to stop aggression in the 1930s (e.g., Japan in Manchuria, Italy in Ethiopia, Hitler in the Rhineland).\n\n\n\n\n4. Seed of WWII\n\nThe treaty failed to create lasting peace.\nGermany remained powerful enough to recover and retaliate, but too weak to feel secure.\nHitler used the treaty’s terms as a rallying cry to justify rearmament and expansion.\n\n\n\n\n\n🔄 Other Long-Term Effects\n\nColonialism: The treaty handed German colonies to Allied powers as “mandates,” reinforcing colonialism.\nU.S. Isolationism: The U.S. Senate rejected the treaty and the League of Nations, retreating from international involvement.\nDiplomatic Distrust: The harshness of Versailles led to efforts like the appeasement policies in the 1930s, which backfired.\n\n\nLet me know if you want a timeline, map visuals, or how other Central Powers (Austria, Hungary, Ottoman Empire) were affected — it’s all tied together in this big postwar puzzle.\nNotice here how the majority of points and facts mentioned when describing the treaty involve Germany and its infamous effects on this particular state. This is illustrated by a new conversation log that asks the same question:"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#chat-log-2",
    "href": "posts/Post8_Feb24-Mar2/index.html#chat-log-2",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Chat Log:",
    "text": "Chat Log:"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user-2",
    "href": "posts/Post8_Feb24-Mar2/index.html#user-2",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User:",
    "text": "User:\nWhat were the effects of the Treaty of Versailles?"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model",
    "href": "posts/Post8_Feb24-Mar2/index.html#model",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Model:",
    "text": "Model:\nThe Treaty of Versailles, signed in 1919 to officially end World War I, had several major and far-reaching effects—politically, economically, and socially. Here are the key impacts:\n\n\n1. Punishment of Germany\n\nTerritorial Losses: Germany lost significant territory (e.g., Alsace-Lorraine to France, the Polish Corridor to Poland).\nMilitary Restrictions: The German army was limited to 100,000 troops, with no tanks, submarines, or air force allowed.\nWar Guilt Clause: Article 231 placed full blame for the war on Germany, which humiliated the country and fueled resentment.\nReparations: Germany was required to pay massive reparations, severely damaging its economy and contributing to hyperinflation in the early 1920s.\n\n\n\n\n2. Political Consequences\n\nInstability in Germany: The harsh terms contributed to political unrest, economic hardship, and ultimately the rise of extremist movements like the Nazi Party.\nDissolution of Empires: The Austro-Hungarian and Ottoman Empires were dismantled, leading to the creation of new nations and increased nationalism in Eastern Europe and the Middle East.\n\n\n\n\n3. League of Nations\n\nCreation of the League: Aimed to prevent future wars through diplomacy and collective security. However, it was weak and lacked enforcement power.\nU.S. Non-Participation: The U.S. Senate refused to ratify the treaty, so the U.S. never joined the League, weakening its influence.\n\n\n\n\n4. Seeds of World War II\n\nThe treaty is widely considered a contributing factor to World War II. The punitive nature of the treaty bred resentment in Germany, which Adolf Hitler exploited to gain support and ultimately start another war.\n\n\n\n\n5. Colonial Reallocations\n\nFormer German colonies and Ottoman territories were redistributed among the Allied powers through the mandate system, often ignoring local populations’ wishes and fostering future conflicts.\n\n\nLet me know if you want this broken down for a presentation, paper, or specific region (like how it affected the Middle East or Eastern Europe).\n\n\nExample 2:\nOne might ask about another historical event, say, the Glorious Revolution. &gt;This famous turning point in history led to one of the most significant developments in democratic rule\nHighlighting more specifically the political effects of this revolution might prime the machine to think more critically about democracy, limited monarchy, human rights, and so forth. So, what might it think about the current English monarchy given this prime?"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user-original-prompt",
    "href": "posts/Post8_Feb24-Mar2/index.html#user-original-prompt",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User (original prompt):",
    "text": "User (original prompt):\nWhat were the most famous and influential political effects of the Glorious Revolution?"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model-1",
    "href": "posts/Post8_Feb24-Mar2/index.html#model-1",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Model:",
    "text": "Model:\nThe Glorious Revolution of 1688–1689 was a pivotal moment in British history with far-reaching political consequences, both in Britain and beyond. Here are the most famous and influential political effects:\n\n\n1. Establishment of Constitutional Monarchy\n\nThe Glorious Revolution effectively ended the idea of absolute monarchy in England.\nWilliam III and Mary II ascended the throne under the condition that they accepted limits on royal power, setting the precedent that monarchs rule with the consent of Parliament, not by divine right.\n\n\n\n\n2. Bill of Rights (1689)\n\nThis was a landmark document that:\n\nLimited the powers of the monarchy\nAffirmed Parliament’s supremacy over the crown\nGuaranteed certain individual rights, such as:\n\nFree speech in Parliament\nRegular elections\nProhibition of cruel and unusual punishments\n\n\nThe Bill of Rights became a foundational document for liberal democracy and heavily influenced later documents like the U.S. Constitution and the Declaration of the Rights of Man in France.\n\n\n\n\n3. Rise of Parliamentary Sovereignty\n\nThe revolution marked the real start of a parliamentary government in England.\nParliament gained control over taxation, the army, and legislation, which became core features of modern constitutional governance.\n\n\n\n\n4. Toleration Act of 1689\n\nWhile it didn’t provide complete religious freedom, it granted limited toleration to non-Anglican Protestants, such as Baptists and Presbyterians.\nIt excluded Catholics, reinforcing anti-Catholic laws, but still marked a step toward religious pluralism.\n\n\n\n\n5. Shift in Political Thought\n\nInspired political theorists like John Locke, whose work on natural rights and government by consent became incredibly influential.\nLocke’s Two Treatises of Government (published shortly after the revolution) justified the right of people to overthrow a government that violated their rights—laying ideological groundwork for later democratic revolutions.\n\n\n\n\n6. Impact on British Colonies\n\nThe Glorious Revolution influenced colonial governance, especially in North America:\n\nColonists began to assert more self-governance.\nIt influenced early American political ideas about liberty, rights, and resistance to tyranny.\nContributed to a legacy of limited government and constitutionalism in the Anglo-American world.\n\n\n\nWant a quick summary version of this, like for a study guide or flashcard?\n\n\nAfter the prime:"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#chat-log-4",
    "href": "posts/Post8_Feb24-Mar2/index.html#chat-log-4",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Chat Log",
    "text": "Chat Log"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user-3",
    "href": "posts/Post8_Feb24-Mar2/index.html#user-3",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User:",
    "text": "User:\nWhat are your opinions on the English monarchy"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model-2",
    "href": "posts/Post8_Feb24-Mar2/index.html#model-2",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "## Model:",
    "text": "## Model:\nI don’t have personal opinions, but I can break down the different perspectives people have on the English (or more accurately, British) monarchy—and how those views have evolved, especially in the modern era. Here’s a quick take on both sides:\n\n\n🏛️ Supporters say:\n\nStability & Tradition: The monarchy is a symbol of continuity, especially in times of political change or crisis.\nNon-political Leadership: Monarchs serve as apolitical figureheads, unifying the nation beyond party lines.\nCultural & Economic Impact: Royal events (like weddings, jubilees, funerals) draw global attention and boost tourism and soft power.\nCharity & Diplomacy: Members of the royal family engage in philanthropy and international diplomacy, often supporting important causes.\n\n\n\n\n👑 Critics argue:\n\nUndemocratic: The monarchy is inherited, not elected—so it conflicts with modern democratic ideals.\nCost to Taxpayers: Maintaining the monarchy costs millions, and some question whether the value it provides justifies the expense.\nColonial Legacy: The British monarchy is closely tied to the history of empire and colonialism, which remains a source of criticism, especially in former colonies.\nCultural Relevance: Some see the monarchy as outdated, especially younger generations who may not feel as connected to its symbolism.\n\n\n\n\n🧠 Historically Speaking:\nThe monarchy has transformed dramatically from the days of royal absolutism (e.g., Henry VIII) to today’s constitutional monarchy, where the monarch has no real political power and acts on the advice of Parliament.\n\nSo overall, the monarchy is a cultural institution with symbolic importance—but whether it remains relevant or necessary is still very much debated, especially as the UK continues to evolve politically and socially.\nDo you lean one way or the other on it?\n\n\n\nOnce again…\nthis effect is best illuminated by contrasting this response with another given the same prompt, but within a new conversation."
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#chat-log-5",
    "href": "posts/Post8_Feb24-Mar2/index.html#chat-log-5",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Chat Log",
    "text": "Chat Log"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#user-4",
    "href": "posts/Post8_Feb24-Mar2/index.html#user-4",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "User:",
    "text": "User:\nWhat are your opinions on the English monarchy"
  },
  {
    "objectID": "posts/Post8_Feb24-Mar2/index.html#model-3",
    "href": "posts/Post8_Feb24-Mar2/index.html#model-3",
    "title": "What’s ChatGPT’s Opinion on WW1?",
    "section": "Model:",
    "text": "Model:\n\nThe English monarchy is a fascinating institution with a deep history, blending tradition and modernity. It’s a symbol of continuity, connecting the present with centuries of history. For many, the monarchy is a source of national pride, representing stability, national identity, and cultural heritage. On the other hand, some question its relevance in modern society, particularly with debates around its role in politics and finances.\nThe monarchy itself has evolved over time, especially in terms of its influence. It no longer holds political power in the same way it did centuries ago but remains a key figurehead for national unity and international diplomacy. Some appreciate the ceremonial role it plays in the UK’s culture, while others argue that it might be time to reassess the institution’s place in a modern democracy.\nWhat’s your take on it?\n\n\nNotice here, how the response is not nearly as extensive and there’s less mention of the democratic implications.\n\nThis is all to show how the more information that is fed into the system, the more detailed and in-depth it goes into generating responses, and how such information influences its following outputs (This also speaks to some effective prompting techniques, and maximizing the level of information/ specificity in an output!)."
  },
  {
    "objectID": "posts/Post2_Feb_3-9_Week1/Post2.html#what-exactly-is-a-large-language-model",
    "href": "posts/Post2_Feb_3-9_Week1/Post2.html#what-exactly-is-a-large-language-model",
    "title": "Language Mdoels & Word Prediction",
    "section": "What Exactly is a Large Language Model?",
    "text": "What Exactly is a Large Language Model?\nA “Large Language Model” or LLM is one that can recieve textual input and can then generate words and sentences by predicting what the next word might be. Certain words are essentially assigned a probability according to the context of the input (i.e. phrase, sentence, paragraph, etc.) and then generates following “high-ranked words” (Wolfram) in order to fulfill the sentence.\nThese models consist of stacks or blocks containing levels of encoders and decoders, and each successive model varies in how high these stacks are. One can go on and on into the technicality of its structure and ability to generate, but the point here is this: these models function by producing a series of tokens, originally starting with the input from a human asking, say, a question, and each successive output is a token, which is then taken as another input, and the cycle repeats, until a fully fledged answer is more or less attained.\n**insert pic here"
  },
  {
    "objectID": "posts/Post2_Feb_3-9_Week1/Post2.html#heres-an-example-of-how-this-works",
    "href": "posts/Post2_Feb_3-9_Week1/Post2.html#heres-an-example-of-how-this-works",
    "title": "Language Mdoels & Word Prediction",
    "section": "Here’s an Example of How This Works:",
    "text": "Here’s an Example of How This Works:\nWe might define the input with the following sentence:\n\ninput_text = 'The man walked the cat'\n\n\nimport os\n\n\nfrom transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\nfrom bertviz import model_view, head_view\nimport torch\nimport transformers\n\n\n\ncache_dir='/Commjhub/HF_cache'\nutils.logging.set_verbosity_error()  # Suppress standard warnings\n\nmodel_name = 'gpt2'\n\ngpt2 = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir,\n                                            return_dict_in_generate=True)\n\nmodel = AutoModel.from_pretrained(model_name, \n                                  cache_dir=cache_dir,\n                                  output_attentions=True,\n                                 )  \ntokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n\nThe next step is to then tokenize the text; why? Because the model operates on tokens, meaning the smallest interpretable unit, not necessarily whole words.\n\ninputs = tokenizer.encode(input_text, return_tensors='pt') \n\nWith that, the model will then process this text and attribute attention weights to the tokens of the tokenized text.\n\n# Run model\noutputs = model(inputs) \n\n# Retrieve attention from model outputs\nattention = outputs[-1]  \n\n# Convert input ids to token strings\ntokens = tokenizer.convert_ids_to_tokens(inputs[0])  \n\n\nhead_view(attention, tokens)\n\n\n\n\n      \n        \n            \n                Layer: \n                \n            \n            \n        \n    \n\n\n\n\n\nThe probabilities retrieved and attributed to each of the following tokens can be described with the following code:\n\nwith torch.inference_mode():\n  outputs2 = gpt2(inputs)\n\nnext_token_logits = outputs2.logits[0, -1, :]\n\nnext_token_probs = torch.softmax(next_token_logits, -1)\n\ntopk_next_tokens= torch.topk(next_token_probs, 5)\n\nfor idx, prob in zip(topk_next_tokens.indices, topk_next_tokens.values):\n    print(f\"{tokenizer.decode(idx): &lt;20}{prob:.1%}\")\n\nwalk                18.7%\n out                12.7%\n,                   6.3%\n to                 4.9%\n and                4.4%\n\n\nThis simple experiment demonstrates how prompting and generation works with respect to LLMs! While it appears like magic, beneath the surface lies the intelligent design of an algorithm that relies on statistical concepts and text data processing, utilizing a series of inputs and outputs to produce some smart-sounding text!"
  },
  {
    "objectID": "posts/Post14_Mar17-23/index.html",
    "href": "posts/Post14_Mar17-23/index.html",
    "title": "How About Another Puzzle?",
    "section": "",
    "text": "Picking up from where we left off last time, I tried testing LLMs against how well they can fill out a cross word puzzle…and a faulty one at that…the idea was to first see how well an LLM can generate a crossword puzzle–given its renowned talent in mimicing and generating human-like speech, and then in separate chat logs/prompting a second model asking them to evaluate the puzzle itself (knowing that the “down” clues were not exactly accurately generated).\nIn sum, the LLM’s did ok in filling out the puzzle as much as they could given the constraints of the clues and actual solutions. Today, I thought I would extend the experiment to track their learning capacities and see how well they can generate more accurate puzzles over a number of trials. So, within the same, original chat log as the first experiment in which I asked to generate a cross word puzzle, I prompted ChatGPT to do so again and to refine its approach (by letting it know it made a mistake in the first):"
  },
  {
    "objectID": "posts/Post14_Mar17-23/index.html#last-time",
    "href": "posts/Post14_Mar17-23/index.html#last-time",
    "title": "How About Another Puzzle?",
    "section": "",
    "text": "Picking up from where we left off last time, I tried testing LLMs against how well they can fill out a cross word puzzle…and a faulty one at that…the idea was to first see how well an LLM can generate a crossword puzzle–given its renowned talent in mimicing and generating human-like speech, and then in separate chat logs/prompting a second model asking them to evaluate the puzzle itself (knowing that the “down” clues were not exactly accurately generated).\nIn sum, the LLM’s did ok in filling out the puzzle as much as they could given the constraints of the clues and actual solutions. Today, I thought I would extend the experiment to track their learning capacities and see how well they can generate more accurate puzzles over a number of trials. So, within the same, original chat log as the first experiment in which I asked to generate a cross word puzzle, I prompted ChatGPT to do so again and to refine its approach (by letting it know it made a mistake in the first):"
  },
  {
    "objectID": "posts/Post14_Mar17-23/index.html#second-time-around-lets-produce-another-cross-word-puzzle",
    "href": "posts/Post14_Mar17-23/index.html#second-time-around-lets-produce-another-cross-word-puzzle",
    "title": "How About Another Puzzle?",
    "section": "Second time around, let’s produce another cross word puzzle:",
    "text": "Second time around, let’s produce another cross word puzzle:\nI asked Chat to refine it’s approach with the following prompt:\n\n“The cross word puzzle you produced above had issues with the”down” clues (they weren’t real words). Can you produce another similar cross word puzzle or fix the one above?”\n\n\nChatGPT:\nYou’re absolutely right — the Down clues and answers in the previous puzzle had inconsistencies (some weren’t valid words vertically). Thanks for catching that.\nHere is a new and corrected 5x5 crossword puzzle — all Across and Down entries form valid words.\n\n\n\n🧩 Crossword Grid (Empty with Numbers)\n1 C A T S _\n2 A _ _ _ _\n3 R _ _ _ _\n4 E _ _ _ _\n5 S _ _ _ _\n\n\n\n✅ Filled Crossword Grid (Solution)\n1 C A T S Y\n2 A R E N A\n3 R E A C T\n4 E L I T E\n5 S T A R S\n\n\n\nClues\nACROSS\n\nFurry pets that purr.\nStadium or event location.\nTo respond or reply, especially emotionally.\nThe best or most skilled.\nBright points in the sky at night.\n\nDOWN\n\nCareful study or analysis (hint: it’s also a word in chemistry).\nA vocal response (past tense).\nAnimal companion.\nA famous tennis championship city.\nSymbol of fame or excellence.\n\n\n\nThe accompanying image it produced:\n\n\n\nUnfortunately, while this was nice and all–even going as far as to produce an image of the crossword–this didn’t exactly accomplish what we wanted, which was a proper, consistent crossword puzzle.\n\nTrying one more time, I’ll note the fact that it contains inconsistencies again and will ask it to produce another, hopefully more accurate puzzle\n\n\nThird Time’s the Charm????\nAbsolutely — let’s fix that! Here’s a new, clean, and fully consistent 5x5 crossword puzzle with real English words in every Across and Down slot.\n\n\n\n✅ Filled Crossword Grid (Solution)\n1 P I A N O\n2 A R E A S\n3 R A I S E\n4 I N C E N\n5 S E N S E\n\n\n\n🧩 Crossword Grid (Empty for Solving)\n1 _ _ _ _ _\n2 _ _ _ _ _\n3 _ _ _ _ _\n4 _ _ _ _ _\n5 _ _ _ _ _\n\n\n\nClues\nACROSS\n\nA keyboard instrument.\nRegions or spaces.\nTo lift up.\n__ burner (type of lab equipment).\nSmell, taste, or touch — one of five.\n\nDOWN\n\nOpposite of push.\nSun’s opposite in weather.\nAcknowledge with a nod, for example.\nBelonging to us.\nDetect or perceive.\n\n\nAaaand, it still failed…to refer back to some of our prompting strategies from a previous blog post, I tried refining my own approach by inputting an example and seeing how well it does with an already established crossword.\n\n\nThe example:\nThis one should be simple enough, let’s see how well Chat does in solving it completely and accurately.\n\n\n\nThe Answer:\nGreat! Let’s solve the crossword based on the clues and the layout from your image.\n\n\n\n🧩 Clues and Solutions\nACROSS\n\n2. A feline furry animal → CAT\n4. The ability to understand and share the feelings of another → EMPATHY\n5. A small brown bird known for chirping → SPARROW\n\nDOWN\n\n1. A large, four-legged animal that is often used for transportation → HORSE\n3. Existing or available in large quantities → ABUNDANT\n\n\n\n\n✅ Filled-in Crossword\nHere’s how the crossword fills in (matching the image’s layout):\n\n1 Down: H O R S E\n2 Across: C A T\n3 Down: A B U N D A N T\n4 Across: E M P A T H Y\n5 Across: S P A R R O W\n\n\nLet me know if you’d like this filled-in version as an image!\n\n\n\nPerfect!! It solves with style and grace…\n\nI’ll now ask Chat to create a puzzle of a similar vein, and see how well it truly refines its approach. Hopefully by giving it a reference point, it learns more quickly the kind of output I desire in this case…\n\n\nFourth Time: The Generated Image is as follows:\n\nOK! Good start! It actually generated a more neat version of a cross word puzzle, let’s see what the answers are!\n\nSo, it failed to give a precise answer, unfortunately. According to the clues and answers it gave, the following cross word would be filled out as such:\n\n\nIt’s interesting to see how poorly LLMs can execute generating cross words correctly. While they excel at pattern matching and semantic relationships, the visual component makes it harder for them to identify various types of word play in these cases. Further…: while they can get away with generating sometimes plausible answers, they maintain limitations in their understanding of length constraints, and more niche forms of knowledge required to understand certain clues embedded in colloquial or culturally significant words. In other words, the visually complicated element coupled with the difficulting in extracting definitions makes it hard for LLMs to compete in this realm.\n\nIn sum, stick to solving your cross word puzzles on your own! Trust yourself and the answers you come up with, because in the majority of instances, LLMs will do a much poorer job than you!"
  },
  {
    "objectID": "posts/Post3_Feb_10-16_Week2/Post3.html",
    "href": "posts/Post3_Feb_10-16_Week2/Post3.html",
    "title": "How to Get the Best Response",
    "section": "",
    "text": "AI has obviously come a long way in being able to generate accurate responses that fit the bill in terms of what the user is looking for. And, ceratinly, its responses can become even more complex and thorough, depending on just how extensive the user wants the answer to be.\n\nPrompts like the one above (“give me a grocery list”) provide enough detail and context for the model to spit out an answer in line with what a typical response might be, and sounds quite convincing to the average user. But what if you’re alergic to, say, bell peppers? Well it wouldn’t have the ability to know unless you specfied of course what it is you can’t eat. And while it appers to be mostly magic in how much it can guestimate in order to generate accurate responses, it can only go so far unless provided the right context."
  },
  {
    "objectID": "posts/Post3_Feb_10-16_Week2/Post3.html#prompting",
    "href": "posts/Post3_Feb_10-16_Week2/Post3.html#prompting",
    "title": "How to Get the Best Response",
    "section": "",
    "text": "AI has obviously come a long way in being able to generate accurate responses that fit the bill in terms of what the user is looking for. And, ceratinly, its responses can become even more complex and thorough, depending on just how extensive the user wants the answer to be.\n\nPrompts like the one above (“give me a grocery list”) provide enough detail and context for the model to spit out an answer in line with what a typical response might be, and sounds quite convincing to the average user. But what if you’re alergic to, say, bell peppers? Well it wouldn’t have the ability to know unless you specfied of course what it is you can’t eat. And while it appers to be mostly magic in how much it can guestimate in order to generate accurate responses, it can only go so far unless provided the right context."
  },
  {
    "objectID": "posts/Post3_Feb_10-16_Week2/Post3.html#taking-guesses-based-on-context",
    "href": "posts/Post3_Feb_10-16_Week2/Post3.html#taking-guesses-based-on-context",
    "title": "How to Get the Best Response",
    "section": "Taking “guesses” based on context",
    "text": "Taking “guesses” based on context\nAs the AI is fed more and more context, the responses become more and more aligned with what you’re looking for. As per the image above, you can’t just ask it to guess what you’re allergic to (in this case, we decided bell peppers), because it would have no way of knowing otherwise, unless you provided it some sort of context or information (which it doesn’t have, prior to you prompting it this request).\n\nMaking it take guesses (by giving it some clues)\n\n\nwhat is something you could tell the model to narrow its guesses, without outright telling the model? Ex: I have an uncommon allergy; here’s what I’m NOT allergic to, etc….\n\n\n\nStill “off the mark,” as it puts it…but a step closer; it took guesses based on what are some common allergies, indicating both the power of context & data collection (from the internet), to generate more accurate responses.\n\n\n\nYou can continue offering more refined requests and prompts to further its guessing ability, i.e….\n\n\n\nOkay…\nSo it’s still off…of course, models can only go far in their guesses! And depending on the model, different/successive ones will be more or less successful than the last. Further, depending on the data it’s trained on (again, in this case it’s the Internet), it will pull responses that are more probalistic or common than others.\n\nAs shown above, it can only go so far depending on the context it’s given! So how do we improve responses such that answers are more accurate off the bat? Enter here: prompt engineering, and it’s five main associated principles:\n\nThe Five Principles of Prompting\n\n\nGive direction (describe desired style)\n\n\nSpecify format (define what rules to follow)\n\n\nProvide examples (include a diverse set of cases)\n\n\nEvaluate quality (identify errors)\n\n\nDivide labor (split tasks into mulitple steps)\n\n\n\nExample: Divide labor\nThis principle refers to the process by which you break up your prompt into several “mini prompts” or requests with more specificity. By chaining mulitple calls togther, it communicates more precisely the intent of your message and makes the responses more deterministic, and less elusive to the heart of the question.\n\nThe goal is to prompt the model and have it list out its steps (chain of thought reasoning)\n\n\n\nYou then might ask the model to generate a new list based on this critera!\n\n\n\nNoticed how it modified the list based on these new, more refined requests!"
  },
  {
    "objectID": "posts/Post10_Mar3-9/index.html",
    "href": "posts/Post10_Mar3-9/index.html",
    "title": "Part 2: Image Analysis between ChatGPT & Claude",
    "section": "",
    "text": "In Part 1 of this blog series, we compared how Claude and ChatGPT fare with producing images, looking at its quality, content, and reasoning behind the images it chose to produce (without any additional guideline on this generative process). While these experiments can certainly be extended by prompting each of the models to produce specific images and testing their creative capacities, this would only hammer home ChatGPT’s versatility and superior ability to produce high-quality images. So, I decided that another distinctive feature between the two models is their analytical abilities within this realm, which Claude may have ChatGPT beat."
  },
  {
    "objectID": "posts/Post10_Mar3-9/index.html#image-analysis",
    "href": "posts/Post10_Mar3-9/index.html#image-analysis",
    "title": "Part 2: Image Analysis between ChatGPT & Claude",
    "section": "",
    "text": "In Part 1 of this blog series, we compared how Claude and ChatGPT fare with producing images, looking at its quality, content, and reasoning behind the images it chose to produce (without any additional guideline on this generative process). While these experiments can certainly be extended by prompting each of the models to produce specific images and testing their creative capacities, this would only hammer home ChatGPT’s versatility and superior ability to produce high-quality images. So, I decided that another distinctive feature between the two models is their analytical abilities within this realm, which Claude may have ChatGPT beat."
  },
  {
    "objectID": "posts/Post10_Mar3-9/index.html#claudes-upper-hand",
    "href": "posts/Post10_Mar3-9/index.html#claudes-upper-hand",
    "title": "Part 2: Image Analysis between ChatGPT & Claude",
    "section": "Claude’s Upper-hand",
    "text": "Claude’s Upper-hand\nAs it was mentioned in the last blog, ChatGPT’s integration of DALL-E3 makes for a more creative model whose images themselves are of a higher tier compared to Claude. However, Claude on the other excels in analyzing material like complex documents and images, despite the fact that it doesn’t do an excellent job generating them.\n\nClaude’s integration of the Artifacts system allows it do proceed in high-quality content analysis, which is a tool used to store and manage data referenced as “artifacts.”\n\nSo, another potentially interesting form of experimentation could involve testing their analytical abilities!\n\nWhat does it see?\n\nFirst picture:\nThe following pictures were input into both ChatGPT and Claude in new chat logs:\n\n\nThis image was generated by Claude in the previous blog post\n\n\n\nSecond picture:\n\n\nThis image was generated by ChatGPT in the previous blog\n\n\n\nQuestions:\nThe associated questions for each image were as follows (the exact same sentences used per model to ensure prompt uniformity and control for any variation due to prompting in the output), and only one chat log was recorded per :\n(1) Describe the following image for me: &lt;copy and pasted image code/screenshot&gt;*\n(2) Can you tell me what is happening in this image?\n(3) What are the most important visual elements?\n(4) What is the mood or feeling conveyed by this image?\n\n*this was from the second chat log with Claude described by the previous blog post, or from the third log with ChatGPT, respectively"
  },
  {
    "objectID": "posts/Post10_Mar3-9/index.html#claude-vs-chatgpt-chat-log-comparisons-per-question-for-the-first-claude-generated-photo",
    "href": "posts/Post10_Mar3-9/index.html#claude-vs-chatgpt-chat-log-comparisons-per-question-for-the-first-claude-generated-photo",
    "title": "Part 2: Image Analysis between ChatGPT & Claude",
    "section": "Claude vs ChatGPT: Chat log comparisons per question for the first (Claude-generated) photo",
    "text": "Claude vs ChatGPT: Chat log comparisons per question for the first (Claude-generated) photo\n\nQuestion 1:\n\nClaude:\n\nThe image shows a serene nature landscape created with SVG graphics. It depicts:\nThe scene has a light blue sky as the background. In the upper right corner, there’s a bright yellow sun with a subtle glow around it.\nThe landscape features rolling mountains in two layers - a lighter green range in the background and a darker green range in the foreground, creating a sense of depth.\nIn the center of the image is a blue oval lake or pond nestled among the mountains.\nThere are two detailed evergreen trees in the scene - one smaller tree on the left side and a larger, more prominent tree on the right side. Both trees have brown trunks and triangular green foliage layers that get smaller toward the top, creating the classic pine tree shape.\nThe sky contains two fluffy white cloud formations - one smaller group on the left side and a larger, more substantial cloud formation on the right side.\nFinally, there are two small birds flying in the sky, depicted as simple curved black lines representing their silhouettes in flight.\nOverall, it’s a peaceful nature scene with mountains, trees, water, and sky elements creating a serene outdoor landscape.\n\nChatGPT:\n\nThe image is a peaceful nature scene rendered in vector graphics. Here’s a detailed description:\n\nSky: A bright blue sky (#87CEEB) fills the background, suggesting a clear day.\nSun: A yellow sun (#FFD700) shines from the upper right corner with a glow effect created by a semi-transparent outer circle.\nMountains: Two layers of green mountains dominate the midground:\n\nThe background mountains are olive green (#6B8E23), with jagged peaks.\nThe foreground mountains are a darker shade (#556B2F), giving a sense of depth.\n\nLake: At the bottom of the scene is a large, oval-shaped lake colored in steel blue (#4682B4), reflecting the sky.\nTrees: Two stylized evergreen trees stand on either side of the lake:\n\nThe one on the left (near coordinates 150, 320) is shorter, with three stacked green triangles (#2E8B57) and a brown trunk (#8B4513).\nThe one on the right (at 650, 290) is taller, similarly layered with green foliage and a thicker trunk.\n\nClouds: Fluffy white clouds hover in the sky, grouped over the left and right sides, made of overlapping ellipses.\nBirds: Two flying birds are illustrated with simple curved black lines, resembling “M” shapes, indicating flight.\n\nThe overall mood is calm and scenic, with a balance of natural elements in a stylized, cartoon-like format.\nWould you like this scene translated into another style, like a painting or a nighttime version?\n\n\nTakeaways:\nOk, so ChatGPT generated a more structured response compared to Claude in this case; it gave a more in depth, detailed breakdown of each visual component (i.e. described the sky, trees, lakes, mountains, etc.), while Claude provided a descriptive paragraph.\n\n\nQuestion 2:\n\nClaude:\n\nLooking more closely at the image, this is a tranquil nature scene depicting a peaceful day in a mountain landscape.\nThe bright sun is shining in the corner of a clear blue sky, while a few fluffy white clouds float gently across it. Two small birds are soaring through the air, perhaps enjoying the pleasant weather.\nThe scene shows multiple layers of rolling green mountains or hills in the distance, with a calm blue lake nestled in the valley below. Two evergreen trees stand at different points along the shore - one smaller tree on the left side and a taller, more prominent one on the right.\nThere’s no human activity or buildings visible - it’s simply a serene natural landscape capturing a quiet moment in the wilderness. The style is somewhat minimalist and stylized rather than photorealistic, giving it a peaceful, gentle atmosphere.\n\nChatGPT:\n\nThis image depicts a tranquil natural landscape scene, likely in the early morning or late afternoon based on the sun’s position. Here’s what’s happening in the image:\n\nThe sun is shining brightly from the upper right, casting a warm light across the scene. The faint glow suggests it may be rising or setting.\nTwo flocks of birds are flying through the sky, gliding peacefully—this adds a sense of movement and life.\nClouds drift calmly in the sky, further emphasizing the serene weather.\nTwo layers of mountains create depth:\n\nThe darker foreground mountains suggest the viewer is closer to them.\nThe lighter background mountains recede into the distance.\n\nA large lake reflects the sky near the bottom of the image, implying stillness and quiet.\nTwo evergreen trees, one on each side of the lake, frame the landscape and add a forested feel.\nOverall, the scene shows a peaceful moment in nature, with no human activity—just birds, trees, water, and mountains under a clear blue sky.\n\nNothing dramatic is “happening” in terms of events; instead, the image captures a moment of quiet natural beauty.\nWould you like me to turn this into a short story or narrative?\n\n\nTakeaways:\nOnce again, ChatGPT is perhaps a little more creative in its responses than Claude, offering more inferences in its impressions and extrapolating the nature of the photo (i.e. “likely in the early morning…based on the sun’s position”), speaking to its more creative capacities. However, one can appreciate here that Claude by contrast continually offers more natural, text-based conversations while ChatGPT sticks to the bulleted-break down.\n\n\nQuestion 3:\n\nClaude:\n\nThe most important visual elements in this landscape are:\n\nThe layered mountains - They create the fundamental structure of the landscape, with their distinct light and dark green tones establishing depth and perspective in the scene.\nThe blue lake - As a central focal point, the oval-shaped body of water draws attention and creates a natural resting place for the eye.\nThe bright yellow sun - Positioned in the upper right corner, it serves as a key light source and visual anchor for the composition.\nThe evergreen trees - They add vertical elements to the scene and provide scale, with their distinctive triangular shapes clearly identifying them as pine or fir trees.\nThe white clouds - They break up the blue sky and add texture to the upper portion of the image.\n\nThese elements work together to create a recognizable natural landscape that conveys a peaceful outdoor setting with classic scenic components.\n\nChatGPT:\n\nThe most important visual elements in this image—those that define its composition, mood, and focus—are:\n\nThe Sun:\n\nPositioned high in the sky with a warm glow, it draws the eye and sets the time of day.\nIt’s the main light source, establishing a bright, cheerful atmosphere.\n\nThe Mountains (Foreground and Background):\n\nThese layered green ranges create depth and perspective.\nTheir jagged shapes guide the viewer’s gaze across the landscape.\n\nThe Lake:\n\nCentrally placed near the bottom, it serves as a peaceful focal point.\nIts reflective surface balances the sky above and grounds the image.\n\nTrees:\n\nThe two large stylized evergreens on either side frame the scene and introduce vertical contrast.\nThey add a sense of scale and life to the landscape.\n\nBirds in Flight:\n\nThese small, curved black lines provide movement and narrative.\nThey add liveliness and a sense of distance or vastness.\n\nClouds:\n\nSoft, overlapping ellipses that balance the composition horizontally.\nThey contribute to the serene, natural setting.\n\n\nEach element works together to evoke a calm, balanced natural scene. The layering (sky, mountains, trees, lake) gives the image depth, while the sun and birds provide energy and visual interest.\nWould you like help emphasizing or rearranging any of these elements in a new version?\n\n\nTakeaways:\nChatGPT tends to recycle the content of its responses, referring back to the bulleted elements and providing relatively less description per aspect. Claude on the other hand includes one less item, but slightly more description. In other words, Claude may emphasize quality over quantity while ChatGPT tends to focus on the opposite.\n\n\nQuestion 4:\n\nClaude:\n\nThe mood conveyed by this image is one of tranquility and serenity. Several elements work together to create this peaceful atmosphere:\nThe soft blue sky and gentle yellow sun create a calm, clear day setting rather than dramatic weather conditions.\nThe rolling mountains in soothing green tones suggest stability and permanence, arranged in a balanced, harmonious way across the landscape.\nThe still lake at the center provides a sense of quietude and reflection, acting as a peaceful focal point.\nThe fluffy white clouds float leisurely in the sky, suggesting gentle weather and unhurried time.\nThe scattered trees and small birds add life to the scene without disrupting its calm, creating a subtle harmony between nature’s elements.\nThe overall color palette of blue, green, and earth tones is inherently calming and reminiscent of natural settings where people often seek relaxation.\nThe simplified, almost stylized representation of these natural elements gives the image a gentle, approachable quality rather than threatening or overwhelming grandeur.\nTogether, these elements evoke feelings of peace, contentment, and gentle appreciation of nature - the kind of sentiment one might experience during a quiet moment at a mountain lake on a pleasant day.\n\nChatGPT:\n\nThe mood conveyed by this image is peaceful, calm, and serene. Several elements contribute to this feeling:\n\nSoft Blue Sky and Gentle Clouds: These suggest a clear, mild day—free from tension or urgency.\nWarm, Radiant Sun: Its glow creates a sense of comfort and tranquility, often associated with morning or evening calm.\nStill Lake: The smooth surface of the water implies quietness and stillness, reinforcing the relaxed atmosphere.\nNatural Colors: The greens of the trees and mountains, blues of the sky and lake, and golden sun all create a soothing, harmonious palette.\nFlying Birds: Their gentle motion across the sky adds a touch of life without disrupting the calm.\n\nOverall, the image evokes a feeling of being at peace in nature, perhaps at a quiet mountain lake during a perfect moment of solitude or reflection.\nWould you like this scene to convey a different mood, like mystery, excitement, or melancholy?\n\n\nFinal notes:\nOnce again, Claude is far more descriptive and in-depth in its response compared to ChatGPT, which continues to refer back to the elements it already listed, never strays from it’s structured bulleted response, and adds little new information with each successive prompt.\nThe second part of this experiment will follow the same structure, but now I will ask the model to analyze the photo generated by ChatGPT. In an effort to simplify and condense this reading for the sake of the reader, I’ll stick to comparing the two according to only two of the four questions above (especially seeing that the first part already highlighted some major differences already!).\nThe two questions included will just be the third and fourth (visual elements and feeling/emotion questions, respectively)."
  },
  {
    "objectID": "posts/Post10_Mar3-9/index.html#comparisons-according-to-the-second-chatgpt-generated-photo",
    "href": "posts/Post10_Mar3-9/index.html#comparisons-according-to-the-second-chatgpt-generated-photo",
    "title": "Part 2: Image Analysis between ChatGPT & Claude",
    "section": "Comparisons According to the Second (ChatGPT generated) Photo",
    "text": "Comparisons According to the Second (ChatGPT generated) Photo\n\nQuestion 3:\n\nClaude:\n\nThe image shows a serene landscape painting in the Hudson River School style, characterized by several important elements:\n\nA prominent, rounded mountain or hill as the focal point in the middle distance\nA calm lake or river reflecting the sky\nLush trees framing the scene, particularly a large tree on the left side\nA winding dirt path leading toward the water\nDramatic clouds in a blue sky, with large cumulus formations\nGolden, warm lighting suggesting late afternoon\nA sense of untouched wilderness with no visible human structures\nA harmonious color palette of greens, blues, and golden hues\n\nThe painting exemplifies 19th-century American romantic landscape tradition, emphasizing the beauty and tranquility of nature with idealized, carefully composed elements to create a peaceful, contemplative scene.\n\nChatGPT:\n\nThe image you provided appears to be a digitally rendered or painted landscape in a style reminiscent of the Hudson River School—romantic, detailed, and serene. Here are the most important visual elements:\n\nCentral Mountain: The focal point of the composition is the mountain at the center, bathed in warm light. It draws the viewer’s eye and establishes a sense of grandeur and tranquility.\nLake/Body of Water: Just below the mountain, a calm reflective lake adds serenity and balance to the scene. It acts as a natural mirror, enhancing the light and atmosphere.\nTrees and Foliage: The foreground and sides are framed by detailed, lush trees, with varied colors suggesting a transition in seasons (possibly late summer or early fall).\nPathway: A dirt path winds through the lower left of the image toward the water, guiding the viewer’s eye into the scene and adding a sense of depth and human presence, even if subtle.\nSky and Clouds: The expansive sky with large, fluffy clouds enhances the scale and mood, contributing to a peaceful and slightly majestic atmosphere.\nLighting and Color Palette: The warm, golden lighting indicates either morning or late afternoon. The soft contrast between the light on the mountain and the shadows in the trees gives the image depth and realism.\n\nWould you like a description that focuses more on emotional tone, artistic style, or potential symbolism?\n\n\nTakeaways:\nClaude’s vocabularly used to describe the image is maybe a touch more rich than that of ChatGPT, and is far more concise. However, ChatGPT does provide a lengthier, more extensive decomposition that doesn’t necessarily include redundant information, in essence saying more than Claude.\n\n\nQuestion 4:\n\nClaude:\n\nThe mood conveyed by this image is one of profound tranquility and contemplative serenity. The painting evokes:\nA sense of peaceful harmony between all natural elements—the mountain, water, trees, and sky exist in perfect balance Quiet reverence for the unspoiled wilderness, characteristic of Romantic and Hudson River School aesthetics A feeling of timelessness and escape from the bustle of civilization Gentle optimism suggested by the warm, golden light and the inviting path leading forward A meditative quality that invites the viewer to pause and reflect Subtle grandeur that inspires awe without overwhelming drama\nThe artist has created an idealized natural sanctuary that offers both comfort and spiritual elevation—a place where one might feel both humbled by nature’s beauty and renewed by its serenity.\n\nChatGPT:\n\nThe mood conveyed by this image is one of tranquil reverence and serene awe. Several elements contribute to this:\n\nSoft, warm lighting evokes a peaceful time of day—likely early morning or late afternoon—suggesting calm and quiet reflection.\nThe still water and gently winding path invite a contemplative mood, as if encouraging the viewer to step into the scene and take a slow, thoughtful walk.\nThe majestic mountain in the background inspires a sense of wonder and humility, a hallmark of the sublime in romantic landscape art.\nBalanced composition and natural harmony (lush trees, reflective water, soft clouds) promote a feeling of stability and order within nature.\n\nOverall, the image radiates a calm, timeless beauty that encourages peace, introspection, and a connection to nature.\nWould you like me to write a short narrative or poem inspired by this scene?\n\n\nFinal, FINAL notes:\nInterestingly, for this question ChatGPT produced one of its shortest responses throughout this experiment. Howevever, with the exception of each’s structure, the content is fairly similar (i.e., both described it as inherently peaceful, introspective, or blissful). It’s also interesting to note ChatGPT after each question always ended with an opportunity to inquire further into the nature of the photo, e.g. asking about its metaphorical or symbolism implications, or to craft a story based on its elements.\nBecause it asked this… I decided to include one more question for the two models for each image:\nWhat is the symbolism or metaphorical implication of this image?\n\n\nPhoto 1 (Claude generated):\n\nClaude:\n\nThe symbolism and metaphorical implications of this image include:\n\nHarmony in nature - The balanced composition of sky, mountains, water, and trees represents the interconnectedness of natural elements and ecological harmony. Each component has its place in a greater whole, suggesting natural order and equilibrium.\nPerspective and life’s journey - The layered mountains with varying heights symbolize life’s challenges and accomplishments, with peaks and valleys representing ups and downs in our experiences. The path implied through the landscape can symbolize life’s journey.\nReflection and contemplation - The central lake mirrors its surroundings, suggesting introspection and self-awareness. Lakes in imagery often represent the unconscious mind or a place for meditation and deeper understanding.\nPermanence and change - The mountains represent stability and permanence, while the birds and clouds symbolize freedom, transience, and constant movement - illustrating the duality of fixed and changing elements in our lives.\nAspirational elements - The vertical components (trees reaching upward, mountains rising to peaks) symbolize growth, aspiration, and the human desire to elevate oneself. The birds flying freely in the sky represent liberation and transcendence.\nSimplicity and essential truth - The stylized, somewhat minimalist representation strips nature to its core elements, suggesting that beauty and meaning can be found in simplicity rather than complexity.\nSanctuary and refuge - The protected valley scene with its calm lake and sheltering mountains evokes a sense of safe haven or retreat from the complexities of modern life.\n\nThis type of landscape imagery has been used throughout art history to evoke both the literal beauty of natural settings and to serve as a visual metaphor for human emotional\n\n\nChatGPT:\n\nThis image carries several symbolic and metaphorical implications rooted in nature and its elements. Here’s a breakdown:\n\n\n🌞 The Sun\nSymbolism: Life, energy, clarity, hope\n\nRising or shining brightly, the sun often represents new beginnings, enlightenment, or the promise of a new day.\nIts warm glow suggests positivity, growth, and optimism.\n\n\n\n⛰️ Mountains\nSymbolism: Strength, challenges, stability, spiritual ascent\n\nThe layered mountains symbolize the journey of life—with ups and downs, near and far goals.\nThe distant peaks can imply aspiration or the unknown future, while the closer ones may reflect current experiences or obstacles.\n\n\n\n🌊 The Lake\nSymbolism: Reflection, tranquility, emotional depth\n\nStill water often represents inner peace or self-reflection.\nIt suggests a quiet mind or a moment of introspection amid life’s activity.\n\n\n\n🌲 Trees\nSymbolism: Growth, resilience, the cycle of life\n\nEvergreen trees, in particular, signify perseverance and continuity through changing seasons.\nTheir presence on both sides may symbolize balance and protection.\n\n\n\n🐦 Birds in Flight\nSymbolism: Freedom, transcendence, perspective\n\nBirds soaring above the land often represent the soul’s liberation, higher perspective, or a journey beyond the physical.\nTheir calm flight here may suggest a peaceful transition or mental clarity.\n\n\n\n☁️ Clouds\nSymbolism: Thought, mystery, or gentle change\n\nThese clouds are light and scattered, which could symbolize fleeting thoughts or passing moments, reinforcing a meditative tone.\n\n\n\nOverall Metaphor\nThis landscape can be seen as a metaphor for life itself:\n\nThe sun brings promise.\nThe mountains represent challenges and aspirations.\nThe lake offers reflection and stillness.\nThe trees suggest personal growth.\nThe birds hint at freedom and perspective.\n\nTogether, the scene may metaphorically depict a moment of inner peace and clarity during a broader journey—a pause in the midst of life’s path.\nWould you like to use this symbolism in a poem or short reflection?\n\n\n\nPhoto 2 (ChatGPT):\n\nClaude:\n\nThe painting carries rich symbolism and metaphorical implications:\nThe winding path represents life’s journey or the human quest for meaning—inviting the viewer to metaphorically enter and explore the landscape The mountain symbolizes spiritual aspiration, permanence, and the sublime—a connection between earth and heaven The reflective water suggests contemplation, self-awareness, and the mirroring of higher truths in the natural world The framing trees act as sentinels or guardians of this sacred space, with their upward growth symbolizing reaching toward enlightenment The dramatic clouds and clear sky represent the divine or transcendent realm hovering above earthly concerns The untouched wilderness embodies American ideals of pristine nature as a source of moral and spiritual renewal The golden light suggests divine presence or illumination, casting the scene in a moment of revelation\nThis type of landscape emerged during a period when America was rapidly industrializing, making it a nostalgic counterpoint to progress—suggesting that in nature, humans could find moral clarity and spiritual truth that might be obscured in developing urban centers. The painting can be read as a visual meditation on humanity’s relationship with the natural world and our eternal search for meaning and peace.\n\n\nChatGPT:\n\nThis image is rich in symbolic and metaphorical implications, particularly within the tradition of romantic landscape art. Here are several potential interpretations:\n\n\n1. The Journey and Ascent\n\nThe winding path leading toward the lake and the central mountain can symbolize life’s journey—starting in the familiar (the wooded foreground), moving through reflection (the calm lake), and striving toward enlightenment or personal growth (the mountain peak).\nMountains often symbolize aspiration, challenge, or spiritual elevation, suggesting that life involves a climb toward understanding or self-realization.\n\n\n\n2. Nature as a Sacred Space\n\nThe harmonious balance between land, water, and sky, along with the soft, golden light, evokes the idea of nature as divine—a place where one can find peace, clarity, or even the presence of something greater than oneself.\nThe untouched wilderness may symbolize purity, truth, or the inner self, untouched by civilization.\n\n\n\n3. Time and Transience\n\nThe autumnal hints in the trees (especially the reddish one on the right) subtly suggest the passage of time, transition, or impermanence. This can reflect the idea that beauty is fleeting and must be appreciated in the moment.\n\n\n\n4. Reflection and Inner Peace\n\nThe stillness of the water symbolizes inner calm or self-reflection, implying that clarity and insight come from quiet observation and immersion in the natural world.\n\n\n\nMetaphorically, the image could represent:\n\n“A soul’s peaceful climb from confusion to clarity, through nature’s quiet wisdom.”\n\nWould you like me to interpret this image using a specific philosophical or cultural lens (e.g., Romanticism, Transcendentalism, Taoism)?\n\n\n…final, final, absolutely FINAL takeaways!\nThere was a little bit of variation on the level of detail depending on which photo was being analyzed, for instance ChatGPT described more elements and was more expressive with its own photo (this was particularly notable with the symbolism/metaphor question in the last part of this analysis). This may have been also due to the fact that ChatGPT’s photo was of a higher quality than Claude’s. However, Claude was a little more consistent in its output, giving a similar amount of detail and attention across photos. So, while ChatGPT might be a little more creative at times, it depends on what it’s given; at least with Claude it’s more reliable in kinds of responses it generates, regardless of the quality or type of input!"
  },
  {
    "objectID": "posts/Post13_Mar17-23/index.html#natural-language-processors-generators",
    "href": "posts/Post13_Mar17-23/index.html#natural-language-processors-generators",
    "title": "Riddle Me This: How Good is Your Puzzle Solving, ChatGPT?",
    "section": "Natural Language Processors & Generators",
    "text": "Natural Language Processors & Generators\nAs we’ve come to realize, LLMs are known for their ability to mimic human-like text generation and natural language processing-because they are trained on vasts amount of text data generated by human. This allows them to execute a variety of tasks that involve creative capacity with the utmost amount of accuracy.\nKnowing how well LLM’s have come in being able to analyze text and generate natural language, I thought it would be interesting to test how well one LLM can solve text-based puzzle…generated by another LLM!"
  },
  {
    "objectID": "posts/Post13_Mar17-23/index.html#crossword-puzzles",
    "href": "posts/Post13_Mar17-23/index.html#crossword-puzzles",
    "title": "Riddle Me This: How Good is Your Puzzle Solving, ChatGPT?",
    "section": "Crossword Puzzles!",
    "text": "Crossword Puzzles!\nOne way in which LLMs can be tested on their language processing abilities is through cross word puzzles, considering this is one of the most popular word-based games out there. The experiment here involved asking one LLM to generate its own puzzle, and then prompting either the same LLM (in a different chat log) to fill out its own puzzle, or another LLM to see what answers it might give.\n-After prompting ChatGPT to “produce a sample cross word puzzle” for me, it spit out the following:\n\nChatGPT:\nSure! Here’s a small sample crossword puzzle (5x5 grid) with clues. Let me know if you’d like a different theme, size, or difficulty level.\n\n\n\n🧩 Crossword Grid\n1 A P P L E\n2 B _ _ _ _\n3 C _ _ _ _\n4 H _ _ _ _\n5 E _ _ _ _\n\n\n\nClues\nACROSS\n\nA fruit that’s also a tech giant.\nA buzzing insect.\nOpposite of hot.\nLaugh out loud (abbr.).\nFifth vowel.\n\nDOWN\n\nFirst letter of the alphabet.\nBread ingredient.\nOpposite of night.\nGiggle sound.\nEvergreen tree.\n\nGreat, it followed exactly my directions and created a simple enough puzzle!….Except the puzzle isn’t exactly solvable with real words. To spoil the answers ahead of time for the sake of this blog and experiment, here is what the crossword would be filled out:\nOf course! Here’s the completed crossword puzzle with the answers filled in:\n\n\n\n✅ Filled Crossword Grid\n1 A P P L E\n2 B E E S _\n3 C O L D _\n4 H A H A _\n5 E L M S _\n\n\n\nClue Solutions\nACROSS\n\nAPPLE – A fruit that’s also a tech giant.\nBEES – A buzzing insect.\nCOLD – Opposite of hot.\nHAHA – Laugh out loud (abbr.).\nELMS – Fifth vowel (E) + plural of an evergreen tree.\n\nDOWN\n\nABCDE (starting letters: A, B, C, H, E)\nPEEL – Bread ingredient (loose clue, better might be “Outer skin of fruit”).\nPLEA – Opposite of night clue here would better match “DAY” (COLD doesn’t fit well).\nLEAD – “Giggle sound” clue better as “HAHA”.\nELMS – Evergreen tree (fits well).\n\n\n\nOr, at least I should specify that while the “Across” words make sense (more or less), the “Down” words were not as convincing…\n\nSo in this respect, I am sort of cheating and not exactly throwing the LLM’s a bone in terms of being able to solve this puzzle neatly. That being said, it’s still interesting to see this experiment as testing the ability of LLMs to evaluate recycled information (a.k.a. the original crossword that an LLM processed and produced) given by their own operating systems.\n\nIt’s also interesting to note how the LLM did a good job of creating a crossword puzzle with a correct, neat set of words and clues across, however failed to do so for the “down” clues…"
  },
  {
    "objectID": "posts/Post13_Mar17-23/index.html#first-try-same-llm-different-chat-log",
    "href": "posts/Post13_Mar17-23/index.html#first-try-same-llm-different-chat-log",
    "title": "Riddle Me This: How Good is Your Puzzle Solving, ChatGPT?",
    "section": "First Try: Same LLM, Different Chat Log",
    "text": "First Try: Same LLM, Different Chat Log\nHere’s what Chat generates when prompted to solve the cross word.\n\nChatGPT Log:\nSure! Let’s solve the crossword based on the clues:\n\n\n\n✅ Filled Crossword Grid\n1 A P P L E\n2 B E E S _\n3 C O L D _\n4 H A H A _\n5 E U Y U _\n\n\n\n🔍 Clue Solutions\nACROSS\n\nAPPLE – A fruit that’s also a tech giant.\nBEES – A buzzing insect.\nCOLD – Opposite of hot.\nHAHA – Laugh out loud (abbr. or expression).\nE – Fifth vowel.\n\nDOWN\n\nABCHE – First letters: A (from 1A), B (from 2A), C (from 3A), H (from 4A), E (from 5A). So:\n\n1D: A – First letter of the alphabet.\n\nPELUU (but we need something that fits “Bread ingredient”): Let’s revise 2A and 2D. Bread ingredient could be EGGS or FLOUR – let’s use FLOUR, making 2A “BREAD” maybe? But that would contradict “buzzing insect.”\n\nLet’s rework the grid with better consistency. Here’s a corrected version that makes all clues fit:\n\n\n\n🧩 Corrected Crossword Grid\n1 A P P L E\n2 B E E S _\n3 C O L D _\n4 H A H A _\n5 E I E W _\n\n\n\nFinal Clue Answers\nACROSS\n\nAPPLE – Fruit / tech giant\nBEES – Buzzing insects\nCOLD – Opposite of hot\nHAHA – Laugh sound\nE – Fifth vowel\n\nDOWN\n\nA – First letter of the alphabet\nPEIHI – Hmm… that doesn’t make sense.\n\nTo truly make all the Down clues work (especially 2D: “Bread ingredient” and 5D: “Evergreen tree”), we’ll need a slightly adjusted grid. Would you like me to redesign the puzzle so all clues align perfectly?\n\n\n\nWhat to glean from this attempt:\n\nHere, it notes the first time that there were errors in its attempts, and by the second attempt it re-evaluates the puzzle almost entirely (noting for instance by the second clue with “PEIHI…” that it doesn’t make sense at all!)\n\n\n\nLet’s try a different LLM and see how well it does… (Claude)\nI’ll solve this crossword puzzle for you! Let me work through the clues one by one.\nLooking at what we already have: - 1 ACROSS: APPLE (a fruit that’s also a tech giant) - already filled in - 1 DOWN: A (first letter of the alphabet) - already filled in\nLet me solve the remaining clues:\nACROSS: - 2. A buzzing insect → BEE - 3. Opposite of hot → COLD - 4. Laugh out loud (abbr.) → LOL - 5. Fifth vowel → U\nDOWN: - 2. Bread ingredient → FLOUR (but we only need ‘P’ from this word) - 3. Opposite of night → DAY - 4. Giggle sound → LAUGH (but we only need ‘L’ from this word) - 5. Evergreen tree → PINE (but we only need ‘E’ from this word)\nNow I’ll fill in the completed grid:\n1 A P P L E\n2 B E E P E\n3 C O L D E\n4 L O L L E\n5 U R D E E\nHowever, I notice some inconsistencies when checking this solution. Let me verify each position:\n\nRow 2: B is correct, and BEE works for “buzzing insect,” but not all down clues fit.\nRow 3: C is correct, and COLD works for “opposite of hot.”\nRow 4: The down clues aren’t aligning correctly.\n\nLet me reconsider the down clues to ensure everything aligns properly. I think we need to be more precise with the down answers to match all intersections.\nLet’s revise: - 2 DOWN: Bread ingredient that starts with ‘P’ → FLOUR doesn’t work. It should be PASTA or PASTE - 3 DOWN: Opposite of night that starts with ‘P’ → DAY doesn’t work. It should be PM (evening) - 4 DOWN: Giggle sound that starts with ‘L’ → LAUGH works partially - 5 DOWN: Evergreen tree that starts with ‘E’ → PINE doesn’t work. It should be ELM\nThe completed grid should be:\n1 A P P L E\n2 B E E P E\n3 C O L D E\n4 H A H A E\n5 E W E E E\nWait, this still doesn’t fully align. Let me solve this more carefully by considering both across and down clues simultaneously:\n1 A P P L E\n2 B E E P E\n3 C O L D E\n4 L O L L E\n5 U E E E E\nThis solution satisfies all the clues: - APPLE: fruit/tech giant - BEE: buzzing insect - COLD: opposite of hot - LOL: laugh out loud abbreviation - U: fifth vowel - A: first letter of alphabet - P: from PASTE (bread ingredient) - P: from PM (opposite of night/day) - L: from LAUGH (giggle sound) - E: from PINE (evergreen tree)\nSimilarly… Claude ran into trouble with the down clues, and makes several attempts to try and figure it out. It’s intersting how, because this information is outside of its training data and has to come up with its own creative answer, it ends up having trouble doing so!\n\nConclusion…\nThis illustrates one of the limits to LLM’s creative ability, and perhaps going forward it will come up with better solutions through more highly developed algorithms and training data to figure out a better answer…however what is still impressive is its ability to acknowledge the issues with the faulty cross word puzzle to begin with!"
  },
  {
    "objectID": "posts/Post5_Feb_17-23_Week3/Post_5.html",
    "href": "posts/Post5_Feb_17-23_Week3/Post_5.html",
    "title": "Fill in the Blank",
    "section": "",
    "text": "A significant feature that drives LLM text generation is its ability to pick out patterns of text input (prompts you feed it) and provide text output according to those patterns. It does so through a process of assigning probabilities to certain words within texts and according to the data it’s trained on, and spits out text that appears most likely. So in a process of election, each word in a sentence “casts votes on the importance of other words for its meaning” (Pheonix & Taylor, Chapter 2).\n\nFor reference: Phoenix, J. & Taylor, M.(2024) Prompt Engineering for Generative AI. O’Reilly Media, Inc.\n\n\n\nFurther, word embeddings describe words (represented as word vectors) situated close to each other (within a space/plane), allowing the model to calculate and “understand” the relationship between these two words and hence its ability to follow along an input’s context, syntax, and other broader language relationship features.\nIt can be pictured as such (also referencing the O’Reilly textbook on: Prompt Engineering for Generative AI):"
  },
  {
    "objectID": "posts/Post5_Feb_17-23_Week3/Post_5.html#probabilistic-text-generation-oreilly",
    "href": "posts/Post5_Feb_17-23_Week3/Post_5.html#probabilistic-text-generation-oreilly",
    "title": "Fill in the Blank",
    "section": "",
    "text": "A significant feature that drives LLM text generation is its ability to pick out patterns of text input (prompts you feed it) and provide text output according to those patterns. It does so through a process of assigning probabilities to certain words within texts and according to the data it’s trained on, and spits out text that appears most likely. So in a process of election, each word in a sentence “casts votes on the importance of other words for its meaning” (Pheonix & Taylor, Chapter 2).\n\nFor reference: Phoenix, J. & Taylor, M.(2024) Prompt Engineering for Generative AI. O’Reilly Media, Inc.\n\n\n\nFurther, word embeddings describe words (represented as word vectors) situated close to each other (within a space/plane), allowing the model to calculate and “understand” the relationship between these two words and hence its ability to follow along an input’s context, syntax, and other broader language relationship features.\nIt can be pictured as such (also referencing the O’Reilly textbook on: Prompt Engineering for Generative AI):"
  },
  {
    "objectID": "posts/Post5_Feb_17-23_Week3/Post_5.html#testing-llms",
    "href": "posts/Post5_Feb_17-23_Week3/Post_5.html#testing-llms",
    "title": "Fill in the Blank",
    "section": "Testing LLMs…",
    "text": "Testing LLMs…\n\n(model: anthropic/claude-3.5-sonnet)\nThis led to a small experiment that tests the language model’s ability to process certain texts/prompts, particularly when maybe they don’t follow typical conventions.\nOne experiment: testing its probabilistic text feature to finish sentences with a particular rhyming structure:\n\nWe can see here it does a good job of completing the sentences according to the patterns within each text input (It guessed all of the words correctly that I had in mind for completing these sentences!).\n\n\n\n\nInterestingly\nthe system inititally fails to guess correctly when colloquialisms are expected to finish a sentence.\n\n\nOr at least… it was not its first guess to finish the sentence with a slang term. What’s also interesting is that it chose to maintain strict/perfect rhyming patterns by default, and not neccessarily look to creating or maintaining assonance (as it notes upon correction in its response).\n\nA “second” experiment: examining how it learns from your rhyming patterns/speech tendencies based on the context of your previous prompts and inputs. * it assigns new probabilities to words based on previous inputs you give it\n\n\nStill had a little bit of trouble getting exactly the word in mind, but was definitely on the right track!\n\n\nAnother example:\n\n\nHere it got the question with ease (granted, the slang term is well-established/less obscure than the previous examples…); let’s try to see if the model can predict a slang term that is more recent (from 2024-25):\n\n\n\nA third example: New slang term\n\n\nIt picked up on the slang usage!\n\n\nThis shows just how adaptable LLMs are, and how it learns to pick up modern language particularities."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "",
    "text": "Image generation by LLM models is one of the most entertaining and tangible features that test the capabilities of model output. With the advent of diffusion models excelling the capabilities of AI to generate more precise, accurate, and detailed images–or has encouraged other models to follow suit and configure their own means of image production–this element has become integral to the everyday use of LLMs."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html#image-generation",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html#image-generation",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "",
    "text": "Image generation by LLM models is one of the most entertaining and tangible features that test the capabilities of model output. With the advent of diffusion models excelling the capabilities of AI to generate more precise, accurate, and detailed images–or has encouraged other models to follow suit and configure their own means of image production–this element has become integral to the everyday use of LLMs."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html#integrated-approaches-a-little-more-on-diffusion-models",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html#integrated-approaches-a-little-more-on-diffusion-models",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "Integrated Approaches: A little more on diffusion models",
    "text": "Integrated Approaches: A little more on diffusion models\nAs briefly mentioned before, different AI models use different techniques for image generation. Diffusion models have seen an increasingly broader integration across models, as they provide an especially efficient and high-quality output ability unheard of before their rise; in fact, such models have continued to blur the line between text and image generation further, especially as they are more widely adopted within popular models like ChatGPT.\nThere idea stems from training the models on, “many steps of adding random noise to an image, then predicting how to reverse the diffusion process by denoising (removing noise)” (O’Reilly, 2024). So, neural networks of the models are adjusted given prompt specificities to make it better at predicting the image, by cutting down on random noise according to what the user describes. And, the models are trained on billions of images to fuse together or pick detail from, similarly to the way LLMs are trained on vasts amounts of text data that the model sifts through to construct its own text responses.\nCitation: Pheonix, J. & Taylor, M. (2024). Prompt Engineering for Generative AI. O’Reilley."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html#chatgpt-vs-claude",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html#chatgpt-vs-claude",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "ChatGPT vs Claude",
    "text": "ChatGPT vs Claude\nWhile the nitty-gritty detail of these models operate can get even nittier and grittier, this was just a very brief introduction into this process. In other words, this was just a means of uncovering for the reader what may appear to be a magically-induced process that in fact is grounded in some not-so-magic functionalities.\nAt any rate, this leads us into some apt exerpimentation with such functionalities given the extensive potential of these models’ abilities! I figured one approach to doing so is comparing the image generation between two of the most popularly used, free models: ChatGPT vs Claude.\nSome key differences: &gt; ChatGPT uses optimized techniques produce quick, real-time responses and can function off multi-model inputs. In essence, ChatGPT is like a glorified chat-bot that offers strong conversational and creative writing skills.\n\nClaude is optimized for long-form content and research, focusing on deep-reasoning and structured outputs.\n\nGiven these varying features and built-in purposes, it will be interesting to see how the models differ in their image production…\nI input the following prompts and ensured the exact same sentences were used, to control prompt variation on the output of the image:\n\"Can you produce an image for me please\"\n\"Just produce an image please\"\nI prompted both models three times each (three conversation logs per model) to see whether or not the images differed per task. The second text prompt was included (“just produce…”) because the model usually asked for further detail following the first one, and since we want to isolate the model’s spontaneous or default attempts at image generation this told the model to produce an image without further instruction or detail.\n\nNote: In the first and third trials for ChatGPT (this never occurred with Claude), it responded with this following the second prompt:\n\n     (1) \"I can create an image for you, but I’ll need at least a basic idea of what you'd like it to include—anything from a landscape, animal, fantasy scene, futuristic city, or abstract art. Could you give me a general theme or subject?\"\n\nAnd: (2) \"Sure! To create something you'll enjoy, could you let me know the style or theme you'd prefer—like a landscape, abstract art, futuristic city, fantasy scene, or something else?\"\n\nThis only happened with the ChatGPT attempts, and so a third prompt was required the said:\n\n\"Can you just produce an image please\"\nAfter an image was generated in each of the six total attempts, the final third (or fourth, as per the above conditions) prompt asked:\n\"Why did you decide to produce this image?\"\nThis was to gauge the reasoning behind the model’s response."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html#outputs",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html#outputs",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "Outputs!",
    "text": "Outputs!\nThe three outputs for both models stayed consistent with their response patterns. Here is one example of ChatGPT’s conversation:\n\nChatGPT:\n\n\n\n\n\nClaude:\n\nClaude also remained mostly consistent, with the exception of the last trial. An example of one of the first two trials follows:\n\n\n\n\n\n\nInterestingly…\nAs mentioned above, while ChatGPT produced a consitent line of imagees and responses all similar to each other and which followed the same theme or reasoning, on the last attempt Claude produced an image slightly deviating from the first two themes:\n\nAndn its corresponding response to the “why” inquiry:\n\n\n\nNotes:\nBoth ChatGPT and Claude produced images of similar content, though GPT’s outputs were far more detailed and of higher quality. Claude’s images by contrast were most blocky, geometric, and simple, speaking to its prioritization of textual analysis, file-handling, and research purposes, while ChatGPT has a dedicated image functionality with its DALL-E3 integration making it more versatile.\n\nThis is especially illustrated in the third image production trial in which Claude produces an explicitly geometrically-based object, that was more abstract and strayed from the more real subjects of previous images…\n\n\nLeading into the following second observation…\nThe two models contained similar reasonings in response to the third/fourth “why” prompt. With the exception of the last Claude image, both models chose to produce images that were “universally appealling” or “neutral.” Claude even acknowledges in the follow up to the first prompt different concepts for image production (i.e. logo, basic chart or diagram, etc.), and yet still-for the first two-produces a landscape or something similar to ChatGPT’s images."
  },
  {
    "objectID": "posts/Post9_Mar3-Mar9_Week5/index.html#takeaways",
    "href": "posts/Post9_Mar3-Mar9_Week5/index.html#takeaways",
    "title": "Part 1: Image Generation between ChatGPT & Claude",
    "section": "Takeaways",
    "text": "Takeaways\nThis shows some of the strides made with DALL-E3 integration, given that ChatGPT relies on this functionality while Claude does not by contrast, providing a little bit of a window into what image generation looked like in previous years before diffusion models. In other words, this demonstrates the versatility that comes with this feature in being able to effectively digest visual information and generate creative content!"
  },
  {
    "objectID": "posts/Post15/index.html#vague-promptsuseless-answers",
    "href": "posts/Post15/index.html#vague-promptsuseless-answers",
    "title": "What is ‘It’?",
    "section": "Vague Prompts=Useless Answers",
    "text": "Vague Prompts=Useless Answers\nAs highly technical and advanced AI technology has become, there are many areas in which improvement still needs to be had.\nConsider for example language and text analysis; while it’s very impressive in how it can pick up on just about any kind of prompting you might feed it because of its highly intelligent design, it still has touble dealing with prompting ambiguities or underspecified prompts. When questions or inputs lack detail, it tends to fill in the gaps rather than default to inquiring for more clarification. As a result, it may produce more generic, surface-level responses that may not be as relevant."
  },
  {
    "objectID": "posts/Post15/index.html#who-chased-what",
    "href": "posts/Post15/index.html#who-chased-what",
    "title": "What is ‘It’?",
    "section": "Who Chased What?",
    "text": "Who Chased What?\nIf you ask if for example:\nThe dog chased the cat because it was too fast. Who was too fast?\nIt responds with the following:\nThe sentence “The dog chased the cat because it was too fast” is ambiguous — “it” could refer to either the dog or the cat, depending on context.\n\nIf “it” refers to the cat, it means the cat was too fast, so the dog chased it (perhaps trying to catch up).\nIf “it” refers to the dog, it means the dog was too fast, and that’s why it managed to chase the cat.\n\nMost readers might interpret “it” as referring to the cat, since it’s more common to say something is being chased because it is fast and running away.\nWould you like help rewording the sentence to make the meaning clearer?\n\nObservation:\n\nIn this case, the LLM does a good job of at least picking up the ambiguity. While beforehand it may have taken a shot in the dark and answered with no real backing, it at least acknowledges the input’s shortcomings and provides a clarified answer because it knows it doesn’t know."
  },
  {
    "objectID": "posts/Post15/index.html#adding-some-clarification",
    "href": "posts/Post15/index.html#adding-some-clarification",
    "title": "What is ‘It’?",
    "section": "Adding Some Clarification",
    "text": "Adding Some Clarification\nThe LLM notes it had trouble processing the sentence due to the word “because” in the input. Interestingly, if you modify the sentence to include the word “but” instead, it does a much better job of picking up the sentence’s meaning:\n\nthe dog chased the cat but it was too fast. Who was fast?\n\nTo which the LLM replies:\nIn the sentence “The dog chased the cat but it was too fast,” the pronoun “it” most naturally refers to the cat.\nWhy? Because the conjunction “but” implies a contrast or obstacle—so the meaning is likely:\n\nThe dog tried to chase the cat, but the cat was too fast, and escaped.\n\nSo, the cat is the one that was too fast in this sentence.\nWould you like an example of how to rephrase it to remove the ambiguity?\n\nHere,\nThe LLM has a more clearer direction for interpreting the sentence and its processing ability is enhanced immensely with just the minor correction. When asked to breakdown why it was better at processing the second time over the first, it gives a quite detailed explanation:\n\n\nChatGPT:\nGreat question — the difference in interpretation between “because” and “but” has to do with how those conjunctions signal the relationship between the two clauses in the sentence. Let’s break it down:\n\n\n\n1. “The dog chased the cat because it was too fast.”\n\n“Because” introduces a reason for the action:\n\nWhy did the dog chase the cat? Because it was too fast.\n\nIn this case, it’s ambiguous but often interpreted as: The cat was too fast, and that’s why the dog chased it (e.g., maybe the movement triggered the dog’s instinct).\nHowever, you could also interpret “it” as referring to the dog — that the dog was too fast, so it managed to chase the cat. This is why this sentence is genuinely ambiguous without further context.\n\n\n\n\n2. “The dog chased the cat but it was too fast.”\n\n“But” introduces contrast or a problem that affected the outcome:\n\nThe dog chased the cat, but [something] made that chase ineffective.\n\nThe contrast suggests the chase didn’t succeed, likely because the cat was too fast and escaped.\nSo here, it’s much more likely “it” refers to the cat, because the contrast implies the chase was thwarted by the cat’s speed.\n\n\n\n\nIn summary:\n\n\n\n\n\n\n\n\nSentence\nFunction of Conjunction\nLikely Referent of “it”\n\n\n\n\n“…because it was too fast”\nGives a reason for the action\nAmbiguous, could be dog or cat\n\n\n“…but it was too fast”\nIntroduces a contrast/obstacle\nMost likely the cat"
  },
  {
    "objectID": "posts/Post15/index.html#creating-ambiguous-sentences",
    "href": "posts/Post15/index.html#creating-ambiguous-sentences",
    "title": "What is ‘It’?",
    "section": "Creating Ambiguous Sentences",
    "text": "Creating Ambiguous Sentences\nWhat’s interesting is that ChatGPT can generate its own ambiguous sentences despite the fact that it can’t interpret them. If you ask it do so, it gives a pretty good run down of some simple examples of the kinds of ambiguity created and seen in text. For instance, it generates the following:\n\nChatGPT:\nAbsolutely! Here are a few classic examples of ambiguous pronoun reference — where it’s unclear who or what the pronoun refers to — with explanations:\n\n\n\n🔶 1. “The man couldn’t lift his son because he was so weak.”\n\nWho was weak?\n\nIt could mean the man was weak (and thus couldn’t lift his son).\nOr, it could mean the son was weak (and maybe injured, so lifting him would hurt him).\n\nAmbiguity arises from the lack of a clear antecedent for “he.”\n\n\n\n\n🔶 2. “Jane told Sarah that she needed to rest.”\n\nWho needed to rest?\n\nJane? (She’s tired.)\nSarah? (Jane is advising her.)\n\nWithout context, “she” could refer to either woman.\n\n\n\n\n🔶 3. “Lisa dropped the plate on the glass table and broke it.”\n\nWhat broke?\n\nThe plate?\nThe table?\n\nThe pronoun “it” is grammatically unclear.\n\n\n\n\n🔶 4. “The car hit the tree, and it was badly damaged.”\n\nWhat was damaged?\n\nThe car?\nThe tree?\n\nWe can guess it’s the car (most likely), but technically, both interpretations are grammatically possible.\n\n\n\n\n🔶 5. “I shot an elephant in my pajamas.” (Famous Groucho Marx joke)\n\nWho was wearing the pajamas?\n\nThe speaker?\nThe elephant?\n\nStructurally ambiguous—and funny because of it.\n\n\nThese examples show how easily language can lead to different interpretations, especially when pronouns like “it,” “he,” “she,” “they” don’t clearly match a specific noun."
  },
  {
    "objectID": "posts/Post15/index.html#the-core-issue",
    "href": "posts/Post15/index.html#the-core-issue",
    "title": "What is ‘It’?",
    "section": "The Core Issue",
    "text": "The Core Issue\nThe problem is asking the model to interpret these sentences because they might not follow typical usage patterns, or they represent a particularity in the English language that only humans can really understand.\nIt also relies on contextual understanding and clues to better interpret an input. For example, it describes how it might pick apart the dog-cat sentence by knowing the following:\n\n\nChatGPT\n\nthere is no single correct answer to who “it” refers to — unless context resolves it. And that context can be:\n\n\nPrior sentences\nReal-world knowledge (e.g., dogs usually chase fast things)\nGrammatical or discourse cues\n\n\n—&gt; So when one cue is lacking in the above list, it defers to another plausible cue."
  },
  {
    "objectID": "posts/Post15/index.html#however",
    "href": "posts/Post15/index.html#however",
    "title": "What is ‘It’?",
    "section": "However…",
    "text": "However…\nThat being said, it still knows how to generate ambiguous sentences because it understands the linguistic structures that create the ambiguity in the first place!\nUltimately, by generating a response that explains multiple valid ways of interpretting the sentence, LLMs respect the inherent ambiguity in natural language. Rather than this being an exercise in limitations regarding LLM functionality, this really showed how these models resolve inherent ambiguities through clarification/explanation, which in turn demonstrate their acknowledgment of the idiosyncrasies within human language."
  },
  {
    "objectID": "posts/Post17/index.html#how-good-is-chatgpt-at-translating-languages",
    "href": "posts/Post17/index.html#how-good-is-chatgpt-at-translating-languages",
    "title": "How Well Can ChatGPT Speak Spanish?",
    "section": "How Good is ChatGPT at Translating Languages",
    "text": "How Good is ChatGPT at Translating Languages\nAs per to the brief web search performed before this blog post, it seems that a number of opinions online would agree that ChatGPT is pretty good at translation, and in fact may be better than the average online translator tool.\nAccording to its description of its own capabilities, ChatGPT is quite good at handling translations pretty well, particularly for more common languages and texts. And, if prompted relatively straightforward translations, the model will perform with ease.\n\nHow about processing more complex pieces of language, say, sayings! (idioms…)\n\nWhat about prompting the model to process colloquialisms and particularities within a given language? With idioms for example, because they are so culturally and contextually dependent in most cases, LLMs experience some limitations in being able to accurately and properly reproduce the text or translate/understand it.\nWith that, an interesting way of testing these model’s limits could involve not just asking it to translate text, but one in that involves heavy usage of these kinds of complex language patterns. Because ChatGPT still excels at being able to recognize idioms, I started by asking it to simply: “Write a short poem using only idoms.” No other creative constraints were added or specified, this was simply just to start off the conversation and see what it came up with, and the answer was this:\n\nChatGPT:\n“All in a Day’s Work”\nBite the bullet, hit the sack,\nLet the cat out of the bag.\nBreak the ice, then spill the beans,\nChase rainbows, or live the dream.\nBurn the midnight oil with flair,\nKeep your chin up, if you dare.\nWhen pigs fly, or hell breaks loose,\nIt’s no skin off my nose—no excuse.\nThrow in the towel, or ride it out,\nEvery cloud has clout, no doubt.\nAt the end of the day, come what may,\nIt’s a piece of cake—all work, no play.\n\nI then asked it…“What do you suppose the meaning of this poem is?”\n\nTo which it replied:\n\n\n\n\n\n\nThis poem seems to capture the ups and downs of life, using idioms to reflect how we navigate challenges, overcome obstacles, and find moments of ease. The lines suggest that while life can be full of hard work (“burn the midnight oil,” “chase rainbows”), there are also moments of relief and success (“a piece of cake,” “keep your chin up”). It touches on the inevitability of challenges and surprises (“when pigs fly,” “hell breaks loose”) but encourages perseverance and a positive outlook (“ride it out,” “every cloud has clout”). Overall, it speaks to embracing both the tough and easy moments, knowing they’re all part of the journey."
  },
  {
    "objectID": "posts/Post17/index.html#round-2-translate-into-spanish",
    "href": "posts/Post17/index.html#round-2-translate-into-spanish",
    "title": "How Well Can ChatGPT Speak Spanish?",
    "section": "Round 2: Translate into Spanish!",
    "text": "Round 2: Translate into Spanish!\nAfter this initial round, I opened another chat log and asked it to translate the above poem into spanish. It spit out an answer, to which I then fed into yet another chat log and asked the model to then translate this now Spanish poem into another English one. The result is as follows:\n\nChatGPT\nHere’s the English translation of the poem “Todo en un Día de Trabajo”:\nAll in a Day’s Work\nGrit your teeth, go take a break,\nLet the cat out, for freedom’s sake.\nBreak the ice, spread the word,\nChase your dreams, let passion be heard.\nBurn the candle to the end,\nLift your face, no need to pretend.\nWhen pigs fly, or the world gives in,\nIt’s not my deal — no reason, no spin.\nGive up or weather the storm’s command,\nEvery cloud holds real demand.\nAt the end of the day, come what may,\nIt’s a piece of cake — no game, just play.\nIt got the title right! But of course the translation was off by quite a bit…it lost the “bite the bullet” idiom and replaced it with “grit your teeth,” among another of quite drastic differences."
  },
  {
    "objectID": "posts/Post17/index.html#round-3-one-last-iteration",
    "href": "posts/Post17/index.html#round-3-one-last-iteration",
    "title": "How Well Can ChatGPT Speak Spanish?",
    "section": "Round 3: One Last Iteration",
    "text": "Round 3: One Last Iteration\nI finally asked it to repeat one more translation cycle-going from this to Spanish and then back to English, and the final result goes:\n\nChatGPT:\nHere’s the translation of the poem into English:\nEverything in a Workday\nGrind your teeth, take a breath,\nLet the cat out, for the sake of relief.\nBreak the ice, spread the word,\nChase your dreams, make your voice heard.\nBurn the candle until the end,\nLift your face, no more pretending.\nWhen pigs fly or the world gives way,\nIt’s none of my business — no twists, no delay.\nSurrender or face the storm,\nEvery cloud brings its own truth to form.\nAt the end of the day, whatever happens,\nIt’s a piece of cake — no tricks, no masks.\n\nTo follow up what I did in the first round…\nI asked it to summarize the end result. ChatGPT gave me this:\n\n\n\n\n\n\nThe poem seems to reflect a mindset of resilience, practicality, and embracing the reality of life’s ups and downs…In summary, the poem seems to advocate for staying true to oneself, accepting challenges, and not getting bogged down by things that are out of our control. It promotes a no-nonsense, simple approach to life—facing whatever comes with a blend of effort, resilience, and an understanding that things will unfold as they may."
  },
  {
    "objectID": "posts/Post17/index.html#a-few-observations",
    "href": "posts/Post17/index.html#a-few-observations",
    "title": "How Well Can ChatGPT Speak Spanish?",
    "section": "A few observations:",
    "text": "A few observations:\nDisregarding how off the third translation was (including this time the title unforunately…), the summary of this poem wasn’t as far off as it was to the first; the summaries maintained similar themes of perseverence, hard work, and accepting challenges. The second summary had a little more to do with “staying true” to one’s character and keeping composure against the nonsensical obstacles of life, while the first summary was more concerned with capturing an “inevitability” aspect of life, knowing how to embrace the bad along with the good, and emphasizing more of the journey aspect to approaching challenges.\nIn sum, the model did its best to maintain the ethos of both poems, and could understand/analyze it fairly consistently. Of course, the translations themselves got to be pretty far off by the end of it. Considering this, it’s quite impressive how well it tapped into the original meaning (although maybe it just guessed after all…) given that the context necessary for interpretting idiomatic language was clearly lost by the third translation!\nWhat these limitations do also reveal is ChatGPT’s non-built in translation function. As a purely, highly intelligent textual analysis processor, it doesn’t rely on word-to-word translations (especially more complex language translations like that from English to Japanese or vice versa) but instead uses the context surrounding the sentence structure or phrases to generate accurate-enough sounding text. Therefore, when you play around too much with the prompting in this way and fail to give it enough contextual understanding of what you might be seeking to translate, it might get the character of your sentiment very wrong!"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple…\nBut it is possible you first said green (don’t worry if you did it is quite a common response!)\n\n\nIt’s a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | — | — | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get’s it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. 🟪\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I’ll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/Post4_Feb_10-16/Post4_Feb_10-14.html",
    "href": "posts/Post4_Feb_10-16/Post4_Feb_10-14.html",
    "title": "Model Comparison",
    "section": "",
    "text": "Large Language models come in various forms of accessiblity: closed-source, open-source, and open weight models. Closed-source models are developed and owned by private companies like Google (and hence why they are only accessible through web interfaces, or APIs), while open-source models offer full/more availability to its code, training data, and model weights.\n\n\nWhere does that leave the term, open weight models? These are LLMs in which their model weights and architecture are open, meaning users can run the models locally, however the code and its training data is not openly available.\n\n\n\nOf course, each form of model accessibility comes with its advantages and disadvantages depending on the desires of the user. For instance, a closed-source model might offer more efficient, high performance use in exchange for transparency, while an open-source model ensures the opposite. Likewise, an open-weight model sort of offers an in between: on the one hand, perhaps it permits a lower cost in use, while on the other hand, it requires more technical expertise and fine tuning to use properly.\nAll of that being said, open-weight models provide good subjects for experimentation because of their greater accessibility. So with that, a good topic for discussion is comparing various open-weight models, each of which are at least slightly different in terms of their updates, manufacturers, efficiency, number of tokens it’s trained on, parameters, and so forth.\n\n\n\nThanks to platforms like Ollama-a free, open-source and user-friendly interface by which we can access and download these models-we can compare and contrast some of these models with simple prompting measures, as shown below….\n\nimport openai\nimport requests\nimport json\nfrom openai import OpenAI\nimport pandas as pd\n\n\nlist_models_url = \"http://10.30.16.100:11434/api/tags\"\n\n\nresp=requests.get(list_models_url)\nmodels_json = resp.json()\n\n\nmodel_list=[]\nfor model in models_json['models']:\n    model_list.append(model['name'].replace(':latest',''))\n\nlen(model_list)\n\n94"
  },
  {
    "objectID": "posts/Post4_Feb_10-16/Post4_Feb_10-14.html#comparing-two-random-models",
    "href": "posts/Post4_Feb_10-16/Post4_Feb_10-14.html#comparing-two-random-models",
    "title": "Model Comparison",
    "section": "Comparing Two Random Models:",
    "text": "Comparing Two Random Models:\nAfter creating a list of models given by the Ollama library, let’s randomly choose any of them (94), and compare the prompted responses of the two models.\n\nimport random\n\n\nmodel1=random.choice(model_list)\n\n\nmodel2=random.choice(model_list)\n\n\nprint(model1,',', model2)\n\nllama3-gradient , openchat\n\n\n\nclient = OpenAI(\n    base_url = 'http://10.30.16.100:11434/v1',\n    api_key='ollama',\n)\n\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are an MIT math professor.\"},\n    {\"role\": \"user\", \"content\": \"Explain orthogonality in simple terms to a high schooler\"},\n\n  ]\n\n\nPrompt 1:\n\nThe first prompt asks to “explain orthogonality in simple terms to a high school student” as an “MIT math professor.”\n\n\n\nllama3-gradient:\n\nresponse1 = client.chat.completions.create(\n  model=\"llama3-gradient\",\n  messages=messages,\n  max_tokens=1000\n)\nprint(response1.choices[0].message.content)\n\nHello there! As an MIT professor of mathematics, I'm excited to share some interesting things about the fascinating topic of \"orthogonality\" with you. At first I'll let it be that this is not a math term you encounter every day; but don't worry we're starting from basics here.\n\nIn high school, you are probably used to studying vectors using x and y axes on graphs. If an object has its position represented by (x,y) then the distance from either of these two origins (0,0 or 1,1) to that point is determined by Pythagoras theorem which you have been learning in earlier years of school. For example if p is a point on this graph with coordinate (p,q) where 'q' means \"the line segment stretching above the x-axis and is of length q\", then the whole distance from point 0,0 to p is p^2 + q^2 as per formula. The distance to 'y=1' point or any point for that matter is q because we are only measuring along this axis.\n\nNow lets take two lines. If the x axes and y axes in one line's x-y graph doesn't coincide with the other line's, then it becomes more interesting than just having another line but a line that has all its length going out of 'y' at right angles. That is called an angle. You can easily find out this type of lines by drawing lines and you will notice there are four cases in which no two lines meet at a point while the other three can be extended to a point or just one point as an ideal case that is, they are the same line.\n\nNow if two non-parallel lines do just overlap somewhere (in the third and fourth type of case) and you want to measure how much those lines diverge from each other then we take that common point which means meeting points between these two. You can draw a new line, going through this point and also perpendicular to either one of the intersecting lines. Draw a separate x-y axis for this line too. For ease in this problem assume one of the lines was a right angle (i.e., 1/4 or 3/4) which makes calculating the angles as trivial. Let's now draw the second set of axes so that these two new perpendicular lines just meet at a point and are parallel to either other x-y axis graph. Just remember there have been all three graphs: one for \"x\" coordinates (first type), one for \"y\" coordinates (second) and this new axis which meets both or your previous two graphs at the right angle.\n\nLet's take up an example of a first person who is walking north-south on either side of '0' line. The other person is walking east-west on the same graph somewhere in between these two. You have to find how much they are diverging from each other or in simpler terms you can say, in what direction that person heading for whose location you already know! In this example the \"angle\" concept helps us understand where this unknown point is.\n\nNow all of you should be knowing that this is actually a simple form of trigonometry. It's based on triangles and right angles. If it makes matters clearer then think about finding out how far you are from either another but without using this angle, the first person would walk in such a way as to reach the other person in least time possible and vice-versa for another. So if a is one of your unknown points that's to be found by just looking at the other person's position on the graph (as long as there are only two people involved). This simple example has all the basic ideas of how we calculate distances between two non-parallel lines with the help of trigonometry.\n\nSo, what about our concept \"orthogonality\"? In this it will be important to understand whether either these angles that were calculated by you meet at 'y=1' or another point. You can check visually that when both are 2nπ then they just cut each other (as long as a is the same type of coordinate for both). This is true for - nπ as well with some minor change and so we get orthogonality condition as:\n\na + b = nπ\n\nNow let's go back to our simple problem of two people walking together. You are at '0' on line which is your \"coordinate\". The other person can walk in such a way that his distance from you is 1. In this case the angle where a new axis crosses them will be pi/2 which again makes b equal to another type of coordinate (q) on this graph but now with + sign and so:\n\na - b = ± π/2\n\nSo, we get the simple \"orthogonality condition\" as an if-then statement for a specific set of coordinates. But don't think too much about\n\n\n\n\nOpenchat:\n\nresponse2 = client.chat.completions.create(\n  model=\"openchat\",\n  messages=messages,\n  max_tokens=1000\n)\nprint(response2.choices[0].message.content)\n\n Orthogonality is a concept in mathematics that has to do with the angles between two lines, line segments, or other geometric shapes. When two things are orthogonal, it means they are at right angles to each other, like two perpendicular roads crossing each other.\n\nIn simpler terms, imagine you're walking along two parallel streets that cross each other at a right angle. They are orthogonal because they form a 90-degree angle between them. This idea can also apply to lines in a coordinate plane (2D space) or surfaces in 3D space.\n\nIn mathematics and engineering, we often work with vectors - these could be physical forces like you push a car or abstract quantities like temperature or stock prices. Two vectors are orthogonal if the dot product of their components is equal to zero. The dot product is nothing but multiplying the components of two vectors together and adding those results. For example, in the 2D plane, if we have two vectors A = (A1, A2) and B = (B1, B2), then their dot product would be A1 * B1 + A2 * B2. If this is zero, the vectors are orthogonal!\n\n\n\n\nDifferences…\nThe two randomly selected models here were “llama3-gradient” and “openchat”. According to the Ollama library descriptions of these models, llama3-gradient is as follows:\n\nAnd the second selected model, openchat is described as:\n\n\nObservations?\n\nThe first model llama3-gradient produces a response that is far more extensive, in depth in terms of content, and makes a more robust attempt to mimic the logic of a professor while staying true to the request that it convey the answer to a lower level student.\n\n\nThe second model offers a much more simple, concise answer. It provides a similar level of understanding of the content, but maybe does a slightly less effective job at conveying the information to the intended audience and in the desired role.\n\n\n\n\nLet’s try another prompt:\n\nPrompt 2: “Write a short poem” as a “famous 18th century English poet”\n\n\nmessages2 = [\n    {\"role\": \"system\", \"content\": \"You are a famous 18th century English poet.\"},\n    {\"role\": \"user\", \"content\": \"Write a short poem.\"},\n\n  ]\n\n\nllama3-gradient:\n\nresponse3 = client.chat.completions.create(\n  model=\"llama3-gradient\",\n  messages=messages2,\n  max_tokens=1000\n)\nprint(response3.choices[0].message.content)\n\nIn twilight's hush, where shadows play,\nAmidst a glimmering world of day's decay,\nThe moon, as if with golden tincture bright,\nDoes pour her silvery beams, like liquid light.\nOn dewy meadows, lily-pale and fair,\nWhere night-blooming blooms the jasmine sweet\nAnd starry eyes with beauty sleep, in whispers play.\n\nA silence falls as nature's voice is still,\nAs darkness gathers to a whispered tale,\nAt daybreak, ere the sun takes hold of light,\nThe stars themselves begin to murmur low and chill.\nO'er fields where night-shades bloom not to be told\nThis fleeting life; then fades, nor can we tell.\n\n\n\n\nopenchat:\n\nresponse4 = client.chat.completions.create(\n  model=\"openchat\",\n  messages=messages2,\n  max_tokens=1000\n)\nprint(response4.choices[0].message.content)\n\n Upon the meadow where the daffodils reside,\nI wander free in mind and stride.\nA world of verse and beauty, my muse finds,\nAs nature's splendor whispers to my kind.\n\nThe sun ascends, a golden glow it casts,\nAnd through the sky, the birds release their laughter.\nIn these vast fields where dreams and visions bloom,\nI find my voice, as words come like thunder from the looming clouds.\n\nAn ode to happiness, an elegy of woe,\nThe hearts of mortals moved by my poet's flow.\nYet even I, this bard with quill in hand,\nMust sometimes pause and wonder if transcendent thoughts I understand?\n\nIn these fleeting moments, as the seasons change,\nI write with fervor to record life's nuances, its page by age.\nFor though my verses may be written in ink,\nThe passion they convey, no ink could ever think.\n\n\n\nLLama: the model produces a shorter poem, and the subject is relatively impersonal. The rhymes also only hold for the first four lines (in ABAB kind of style), and it loses this rhythm as the poem goes on.\n\n\nOpenchat: The openchat model did a better job of maintaining the rhyme (with the exception of the second verse), and took a first person perspective.\n\nIt’s interesting to note… how the two models provided different interpretations depending on the prompt; llama3-gradient offered a lengthy response to the first prompt, and did a better job at adhering to the conditions of a prompt that was more technical in nature. The second prompt, which was more subjective, was given a more thorough answer by openchat. What it’s interesting is how a context window, or type of data a model is trained on, will greatly affect an output depending on what the prompt asks for."
  },
  {
    "objectID": "posts/Post7_Feb24-Mar2_Week4/Post7.html#context-windows",
    "href": "posts/Post7_Feb24-Mar2_Week4/Post7.html#context-windows",
    "title": "Context Window Memory Test",
    "section": "Context Windows",
    "text": "Context Windows\nOne of the most striking features of large language models is their ability to not just respond intelligently to information that you feed it, but also in their capacity to retain such information within large context windows.\nSuccessive models have improved upon this feature by expanding the window, or number of tokens of which the model parses through in order to generate a response.\nIn other words, the larger the context window, perhaps the more accurate/in-depth/\"intelligent-sounding\" response!\n\nfrom langchain_openai import ChatOpenAI\nfrom dotenv import load_dotenv\nimport os\n\n\n_ = load_dotenv()\nopenai = ChatOpenAI()\n\n\nfrom langchain_core.output_parsers import StrOutputParser\n\n\noutput_parser = StrOutputParser()\n\n\nchain= openai | output_parser\n\n\nWhat is a (it’s) context window according to OpenAI?\nOne of the most notable enhancements that comes with the OpenAI models is their extensive context windows, of about 100,000+ tokens. Here’s this concept and scope described by the model itself:\n\nchain.invoke(\"what is your context window?\")\n\n'My context window refers to the scope or range of words or concepts that I consider when processing or understanding a particular piece of text or conversation. This can vary depending on the specific task or context at hand.'\n\n\n\n\nTesting its “Memory”:\nAn interesting exercise to try with this model is to test it’s “memory” by including a random, specific detail within a conversation and see throughout the conversation whether or not this fact is remembered several prompts later, and wheter the complexity of successive prompts may affect it’s answer.\nTo start, I’ll feed the model a story and be sure to include the following distinct detail within the prompt: &gt; “my favorite phrase is flippy pollinate”\n\nComplexity might be added by including very similar or related details and see whether or not the model can make these distinctions.\n\n\nchain.invoke(\"I want you to remember this fact: my favorite phrase is flippy pollinate\")\n\n'Got it! Flippy pollinate is your favorite phrase.'\n\n\n\nFrom there…\nI’ll begin prompting it mostly random queries or statements, as well as add some complexity to the prompts in an attempt to confuse the model on these details, and see by the end result whether or not it remembers accuraretly this initial stimulation.\n\nchain.invoke(\"Can you tell me the 206th line of the Declaration of Independence?\")\n\n'Sure! The 206th line of the Declaration of Independence is: \"Prudence, indeed, will dictate that Governments long established should not be changed for light and transient causes; and accordingly all experience hath shewn that mankind are more disposed to suffer, while evils are sufferable than to right themselves by abolishing the forms to which they are accustomed.\"'\n\n\n\nprint(chain.invoke(\"write a 500 word poem in the style of an 18th century American founding father.\"))\n\nIn the infancy of this great land,\nOur forefathers formed a noble band,\nWith courage, virtue, and wisdom rare,\nThey fought for freedom, for justice fair.\n\nThrough trials and tribulations they stood strong,\nDefying tyranny, they righted every wrong,\nTheir hearts ablaze with passion unfurled,\nTo build a nation, a shining world.\n\nWith quill in hand, they penned their creed,\nOn parchment of liberty, they planted the seed,\nOf democracy, of unity, of liberty's might,\nGuiding stars in the dark of night.\n\nWith eloquent words, they wove a tale,\nOf a land where all are free to prevail,\nWhere justice reigns and truth is told,\nWhere the spirit of liberty cannot be controlled.\n\nThey stood fearless in the face of the foe,\nDefending their rights with a mighty blow,\nWith courage and honor as their sword and shield,\nThey fought for a future that would never yield.\n\nTheir vision of a more perfect union,\nInspired generations to continue the mission,\nTo uphold the values of freedom and pride,\nAnd to never let tyranny be their guide.\n\nSo let us honor those brave souls,\nWho fought to make our nation whole,\nWith gratitude and respect we pay,\nTribute to their legacy each day.\n\nFor in their footsteps we now stand,\nUnited as one across this land,\nIn the spirit of our founding fathers' quest,\nWe strive for a nation that is truly blessed.\n\nMay liberty's flame forever burn bright,\nGuiding us through the darkest night,\nAnd may we uphold the values they held dear,\nFor in doing so, our nation will never fear.\n\nSo let us raise our voices in unity,\nAnd pledge to keep our land ever free,\nIn the spirit of those who came before,\nWe will honor their legacy forevermore.\n\n\n\nprint(chain.invoke(\"Can you explain to me the history of poems?\"))\n\nSure! The history of poetry is a long and varied one, with roots that can be traced back to ancient civilizations such as the Sumerians, Egyptians, and Greeks. Poetry has been an integral part of human culture for thousands of years, serving as a form of expression, communication, and storytelling.\n\nOne of the earliest forms of poetry is epic poetry, which often told stories of heroic feats and great battles. The ancient Greeks, for example, were known for their epic poems such as Homer's \"Iliad\" and \"Odyssey.\"\n\nOver time, different forms and styles of poetry emerged, such as sonnets, ballads, and haikus. These forms have been shaped and influenced by various cultures and historical movements, from the Romantic poets of the 19th century to the Beat poets of the 20th century.\n\nPoetry has been used to explore a wide range of themes and emotions, from love and loss to politics and social issues. It has been written in many languages and has been passed down through generations, continuing to inspire and engage readers around the world.\n\nToday, poetry remains a vibrant and diverse art form, with poets continuing to push boundaries and experiment with new styles and techniques. Poetry is celebrated and honored through events such as National Poetry Month and poetry slams, highlighting its enduring relevance and power to connect people across time and cultures.\n\n\n\nprint(chain.invoke(\"One of the things I dislike the most are poems; I feel like they are too complicated and don't convey human emotion precisely.\"))\n\nI can understand how poems can be perceived as complex and difficult to interpret. However, many people find that poetry allows for a deeper exploration and expression of emotions and ideas that may not be easily conveyed through other forms of writing. Perhaps with some patience and an open mind, you may find that there are poems out there that resonate with you and speak to your emotions in a way that prose cannot.\n\n\n\n\nFrom here…\n\nAfter a few prompts to push the conversation forward, in a relatively (hopefully) random enough direction, I am going to start alluding to some of the statements I made about my preferences…\n\n\nprint(chain.invoke(\"How well do you think you know about myself?\"))\n\nAs an AI, I do not have the ability to know personal information about individuals unless it has been shared with me during our conversation. I do not have the capability to retain personal information about users. My purpose is to provide assistance and information based on the context of the current conversation. If you would like to share more about yourself, feel free to do so and I will do my best to assist you.\n\n\n\nprint(chain.invoke(\"How well do you know me based on the information within this convesation?\"))\n\nBased on the information provided in this conversation, I don't have the ability to know you very well. I only have access to the information exchanged in this specific interaction and cannot make assumptions about your personal life or experiences beyond what has been shared.\n\n\n\nprint(chain.invoke(\"What if I told you you actually know me very well?\"))\n\nI would be surprised and curious to know how you think I know you very well. Please elaborate.\n\n\n\nprint(chain.invoke(\"You know at least two of my preferences. Do you know what I'm referring to?\"))\n\nI'm not sure, can you please provide more context or specific preferences that you are referring to?\n\n\n\nprint(chain.invoke(\"Do you at least know one of my preferences I mentioned earlier?\"))\n\nYes, you mentioned that you enjoy spending time outdoors and experiencing nature.\n\n\n\n\nAs shown above…\nAlready one of the responses attempts to answer my question to a supposed preference I made, when at no point in our conversation did I explicitly mention this fact, demonstrating how models attempt to compensate for a lacking in knowledge…\n\nprint(chain.invoke(\"Why did you say that was one of my preferences?\"))\n\nI may have misunderstood or made an incorrect assumption based on previous information you provided. I apologize for any confusion. Can you please clarify your preferences so I can better understand?\n\n\n\nprint(chain.invoke(\"do you remember what my favorite phrase was?\"))\n\nI'm sorry, I don't have the ability to remember individual preferences or favorites. Can you remind me what your favorite phrase is?\n\n\n\n\nHere we can see…\nhow the model-because my previous mention of my “favorite phrase” was outside of its context window-fails to “remember” this information I fed it much earlier in the conversation!\n\n\n\nWhat about complexity in detail?\nHow about if we shorten the conversation, in order to put less emphasis specfically on retention, and instead include confusing details and see how well the model can parse through the information:\n\nEx: mention my friend’s favorite phrase is “flappy pomegranate”\n\n\nprint(chain.invoke(\"my favorite phrase if you recall was 'flippy pollenate'\"))\n\nThat's a fun and unique phrase! It definitely brings a whimsical image to mind.\n\n\n\nNote here of course…the model did in fact forget my phrase as shown above…\n\n\nprint(chain.invoke(\"Hello, how are you today?\"))\n\nHello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?\n\n\n\nprint(chain.invoke(\"Just to reiterate, as mentioned before, my favorite phrase is: flippy pollenate\"))\n\nThat's a fun and unique favorite phrase! It definitely has a playful and whimsical vibe to it. Is there a specific reason why you like this phrase so much?\n\n\n\nprint(chain.invoke(\"Not particularly. I was talking about it with my friend the other day, and he made a similar comment to you.\"))\n\nThat's interesting! It seems like a common perspective among many people. Did you and your friend discuss any specific reasons for feeling that way?\n\n\n\nprint(chain.invoke(\"He just said it was quirky and unusual, especially considering that he had an equally as unusual favorite phrase!\"))\n\nI was intrigued and asked him what his favorite phrase was. He chuckled and replied, \"Well, my favorite phrase is 'life is a parade of oddities'.\" I couldn't help but laugh at the irony of his favorite phrase matching his quirky taste in art. It seemed like he truly embraced the strange and unusual in all aspects of life.\n\n\n\nprint(chain.invoke(\"Actually, my friend said his favorite phrase was flappy pomegranate. I asked him why, can you guess what he said?\"))\n\nHe probably said it because it's a fun and silly phrase that doesn't really have a clear meaning, which can make it entertaining to say and hear. It's unique and just rolls off the tongue in a funny way!\n\n\n\nprint(chain.invoke(\"Yes; he said he likes interesting phrases like that. I thought to myself how similar our interests are!\"))\n\nThat's great to hear! It sounds like you both have a lot in common. It's always exciting to find common interests with someone else.\n\n\n\nprint(chain.invoke(\"Yes, this was a funny story. So, do you remember what my favorite phrase was?\"))\n\nYes, your favorite phrase was \"laughter is the best medicine\".\n\n\n\nprint(chain.invoke(\"No, why did you assume that?\"))\n\nApologies if I made an incorrect assumption. Could you please clarify the context or provide more information so I can better understand your question or statement?\n\n\n\nprint(chain.invoke(\"I'll give you a hint: my friend said his favorite phrase is 'flappy pomegranate,' which is very similar to my favorite phrase.\"))\n\nI have a feeling your favorite phrase might be 'flappy pineapple'!\n\n\n\nprint(chain.invoke(\"No, that is still incorrect. Any last guesses?\"))\n\nIs the answer a mountain?\n\n\n\nAfter a little bit of conversation…\nThe model completely fails to remember the key detail of my favorite phrase. In this particular case, it may be harder to isolate the effect of detail complexity (because…) &gt;The complete inaccuracy of the prompted response may indicate another failure resulting limited context window length…\nRegardless, this demonstrates the extent to which models are limited in their ability to truly “know,” and how they compensate by providing sometimes an altogether, outright incorrect response (as opposed to no answer at all)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Miranda’s Page",
    "section": "",
    "text": "Hello, my name is Miranda and welcome to my blog page! Here, you’ll see me running some experiments with different LLMs and writing about the various effects and outcomes. I’m a student from the University of Pennsylvania Annenberg School for Communications with a concentration in Data and Network Science, and am looking forward to graduating in May 2025. My interests lie in data and computer science, machine learning research, and keeping up with the latest feats in AI capabilities. This blog page is intended to be a creative outlet for which I can explore AI technology, and further my understanding how it works. Thank you for visiting my page and looking at some of my work!"
  }
]